{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e15ba090",
   "metadata": {
    "id": "e15ba090"
   },
   "source": [
    "# Fine-Tuning LLaMA 3.1 8B on MedMCQA Dataset\n",
    "This notebook fine-tunes the `meta-llama/Llama-3.1-8B-Instruct` model on the `openlifescienceai/medmcqa` dataset using LoRA + Unsloth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jNX2NaBGl_za",
   "metadata": {
    "id": "jNX2NaBGl_za"
   },
   "source": [
    "# Installing Libraries & Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "T81HP0mCl1xz",
   "metadata": {
    "id": "T81HP0mCl1xz"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "# Add imports as desired\n",
    "\n",
    "# Remove explicit torch and transformers installation as they are handled by subsequent installs\n",
    "# and rely on pip to get the correct version for the system's CUDA setup.\n",
    "# !pip install torch==2.3.0+cu118 -f https://download.pytorch.org/whl/torch_stable.html # Removed\n",
    "!pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
    "!pip install sentencepiece protobuf \"datasets>=3.4.1\" huggingface_hub hf_transfer\n",
    "# Install transformers and unsloth. Let unsloth handle this dependency.\n",
    "!pip install transformers==4.51.3 # Removed\n",
    "!pip install --no-deps unsloth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hDi2nAa2tbvK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 333,
     "referenced_widgets": [
      "5a740faa55234c549b26c121c4a6db91",
      "30557398f04f4a25abfe489322734a21",
      "7b448a41084642ee90ffbdab81936c0c",
      "cc3c408faf304404932d23f65088bb9a",
      "b2d49299663f442fbec846fee1443611",
      "f30df2a5031a428da1b9e70b46f1a169",
      "26fc0c7c06b04633b3bf5f7c742970a6",
      "fcb75c50d0084af59035a95f0c8fdfdc",
      "59cc95b46ef641bd84c2e4bae7a5df81",
      "f6c3112031074ea596d76dcf920edc93",
      "50b7ba5e92664944a72c2b06898037c3",
      "c195b8521e9042bba6c24e383e2c5ea0",
      "bf9c89dcfc9548e696fc93115fafb365",
      "502adc2ac8624f98afa52c98ce8f87fd",
      "98e103eceaf347e8a189505923a2d5d2",
      "7ac72bbf9f864a32a6ac589fa70061c4",
      "5962c5e7eee14436a4e3b4a2d429ce6e",
      "797118e2bb1e4213ab1564e6a86b7a40",
      "33ab21a1c9264708882e0c608e00aac1",
      "b71b47250430470bb178fcb8ba5bb469",
      "f731bab8bef24441b643cd214c8834bc",
      "82c34af4ee154da69ddbd8b0ac9298a9",
      "9d296993cc76481bae4b21519efc5e55",
      "4953738d727a43c4b395873d8e51ddc2",
      "959b4fc6d60a47a08ff04184c73e7320",
      "3ac24d73a82e4355b5ce9b5b560da57c",
      "329e3b952cb14d1c9da8d0b58bd4d676",
      "d2b5be1e819b41cbba42c5a7e34b8289",
      "95ae02894ad64711afc0bafd910a4dd0",
      "5033d30920e0418ab06727ad8fe7b01c",
      "c4cabc9305d944529d4e925b1cb026ea",
      "4b3506daef004eb58137bbc8348047d3",
      "aef6c0c2999e4c1390efd7b812c5c29b",
      "01f971d40deb4f1da55c6296678a10e5",
      "2e78ec70841348078cbf4a8f90ef970b",
      "7fdc8d23010946b592a254137b4896ab",
      "8efcbc366d364a2a8726403a60d105ac",
      "f3ba1bedd21f484da92604665a3ce4bb",
      "f49976f1260e4e34bd111dc9ffe67e60",
      "938a0b02b5b44595aecf3740e93c4a22",
      "e2e0b7b278884a789d79edb7c87cb5c3",
      "e46fae5ac906403d98caea215645e2f5",
      "29de082608fa4c8b9313d5cb5a0d44fa",
      "2fa2f16d54294df2890144bdf5611ebe",
      "b00876353ea6477abe96a13391c404c0",
      "88a5607e6af24ea5b56879d2848bbd6d",
      "7f8de94b7f5a42beb81d3544a519a99a",
      "fa06b9bb6ecd46f2b318dfb5a2c003f6",
      "c5b098897eee45c4a211110059b71f7d",
      "cd77cde68ded4b019b152b9fc990731e",
      "62d5aa333c214a799705d63ce9b6a652",
      "a096f93a3a1547eb81891522feb10639",
      "cc7d800b9bb045309d690e581c5ac842",
      "a6a309a29de343c1bc9927b6d184d40e",
      "03b00c9e5d774275bda274ac415608b4"
     ]
    },
    "id": "hDi2nAa2tbvK",
    "outputId": "3ac97efb-a7fe-47ff-b973-1e57627484e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "==((====))==  Unsloth 2025.6.8: Fast Llama patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a740faa55234c549b26c121c4a6db91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c195b8521e9042bba6c24e383e2c5ea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d296993cc76481bae4b21519efc5e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f971d40deb4f1da55c6296678a10e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b00876353ea6477abe96a13391c404c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.6.8 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "# import torch # Removed explicit torch import as unsloth handles it\n",
    "max_seq_length = 256 # Choose any!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage.\n",
    "\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"meta-llama/Llama-3.1-8B-Instruct\",       # Choose a model.\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "\n",
    "# ✅ Fix: Add LoRA adapters to enable fine-tuning on quantized model\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16,\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = True,\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "A0bHi9bLtDUP",
   "metadata": {
    "id": "A0bHi9bLtDUP"
   },
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ip84qz0lsjKF",
   "metadata": {
    "id": "ip84qz0lsjKF"
   },
   "source": [
    "## Building a Function That can build the text column for the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b135467d",
   "metadata": {
    "id": "b135467d"
   },
   "outputs": [],
   "source": [
    "def format_func(example):\n",
    "    options = {\n",
    "        \"0\": example[\"opa\"],\n",
    "        \"1\": example[\"opb\"],\n",
    "        \"2\": example[\"opc\"],\n",
    "        \"3\": example[\"opd\"],\n",
    "    }\n",
    "\n",
    "    # Correct answer index as string\n",
    "    correct_letter = str(example[\"cop\"]).strip()\n",
    "    correct_answer = options.get(correct_letter, \"Unknown\")\n",
    "\n",
    "    key = {\"0\": \"A\", \"1\": \"B\", \"2\": \"C\", \"3\": \"D\"}\n",
    "    answer_prefix = key.get(correct_letter, \"\")\n",
    "\n",
    "    if answer_prefix:\n",
    "        answer_part = f\"Answer: {answer_prefix}. {correct_answer}\"\n",
    "    else:\n",
    "        answer_part = f\"Answer: {correct_answer}\"\n",
    "\n",
    "    # Retrieve explanation and ensure it's a string before stripping\n",
    "    explanation_value = example.get(\"exp\", \"\")\n",
    "    explanation = str(explanation_value).strip() # Convert to string before stripping\n",
    "\n",
    "    if explanation:\n",
    "        explanation_part = f\"Explanation: {explanation}\"\n",
    "    else:\n",
    "        explanation_part = \"\"\n",
    "\n",
    "    question_text = (\n",
    "        f\"<|user|>\\n\"\n",
    "        f\"Question: {example['question']}\\n\"\n",
    "        f\"A. {example['opa']}\\n\"\n",
    "        f\"B. {example['opb']}\\n\"\n",
    "        f\"C. {example['opc']}\\n\"\n",
    "        f\"D. {example['opd']}\\n\"\n",
    "        f\"<|assistant|>\\n\"\n",
    "        f\"{answer_part}\\n\"\n",
    "        f\"{explanation_part}\"\n",
    "    )\n",
    "\n",
    "    example[\"text\"] = question_text\n",
    "    return example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xENFT7qftBUt",
   "metadata": {
    "id": "xENFT7qftBUt"
   },
   "source": [
    "## Applying the map function into entire the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-Rzf9DeqvMis",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337,
     "referenced_widgets": [
      "474354289e6140a48e92ec55889bd19b",
      "3e57f0785afa4dfe85bb71b1b6fb7082",
      "3bb8892a5af54851b535acd8e4780451",
      "1b2c068af4e04a56814a4304e19dfb0f",
      "63bbddd6e6674f2f9ffc4130e7902463",
      "99b23952e8b7496eaa4ef9f2f824c3d6",
      "efea2fc9df9645739183be601f55a3de",
      "75022fa2b4cd49b6ad344ee782596009",
      "584fb24983d84f27bcbc42209cc6b6c4",
      "2420c3501e34474d8480c144f2708250",
      "a44da09af8604157b2eae03ef70f5d35",
      "78813c78dec3495e90b6a7f83aa56322",
      "cedaf6b311b74f1d8a4dc456d8d82ea2",
      "8b47e695f231453485ec393e159491ab",
      "9d025035dd4a45fe976f323d7190ffe5",
      "4e3e97d9336e48ab963a46b9ea05ac1e",
      "d5fa42f24eda4f41af102ea5e2ea7d07",
      "bb5ad6b3311f44dcbdb0852c46c11fda",
      "745e7e728ff143c794cf540e732658e9",
      "ce37d3779a934477bf83553d1f81839d",
      "0d62da196cd5459b83e899aedcf5a214",
      "656ed91bc0524877a20d5876bd0f8e1d",
      "9cd1a33d099c466f8c6131403b59be4b",
      "9e9a846911a24c59bdd8d7cfbb9f1ea6",
      "1112972205164fbcae584b31db45a178",
      "87c90f04afc1414f917883f10fe10527",
      "d97693e3ccbc4dd18fc719510e1cc497",
      "4dd235bfab4845ffabaae48e69a8229a",
      "618f4dc011844395b4c42de784697110",
      "e4de6e7228f846af844097ddac3f1732",
      "dc38f36696ee45798774d9f77c1e11d9",
      "aaf52e64996e4ab0866fcf62df8c3eaa",
      "9a9f271b147b4ed39cc8b9e3a6177498",
      "1d166eacb3824d5ebc8538aae895129e",
      "4030f5a48031468f93c651e7d6a203cb",
      "0bb9aefd47924ecdacdbac86601c2506",
      "a5baf2174cc442289b270f62135cc210",
      "eeda8e0fe3624c2abe571b3a295b9290",
      "36e0173301ab4dc3befa28095e02faf9",
      "b73125acc04b40adb622c26583c6d5a1",
      "65ff6ae28e544835914aef71efeac872",
      "0732929cab6f4ca684a16c6f320cbebb",
      "a464125f00cc4766afb76070aa5fd978",
      "7ce779966d0d46a09ab920af2d2ee7e9",
      "c302b2b224474de3a106c23715313195",
      "365c364b70644a259558e7e1a9dc33f9",
      "46065f8ba9284576bed75e804c025a1c",
      "59d8c03b08774c74afe18bf71136bcc9",
      "51d1830b94b74a659fe306d3229ef576",
      "7648423affa84672afce6ab79fb75a60",
      "8649a449d13a47e291489a93193318f5",
      "d5ee84e0834f4a58a1f6ccb86a78924c",
      "5f00d0b6e29b4d4ea762109ade6f2754",
      "9d7c0443a8494e0db2e7d5a2f0286b36",
      "4483b587a84a4d1099dd082e0f578894",
      "10a9b16aa34a4199ace16a6bd441f293",
      "cf132e354a5c40b983172c680bc9bd45",
      "60d979112c3247b0ba1c5cca6cc3645c",
      "d45633de4f904380a688897bbd75bb6d",
      "504f35ef78674d2b8e8f86ec976f410a",
      "efef3484001e409bb813669767ea54ad",
      "4c75457eb8204c5eb7ec57d274afc811",
      "446a91d79e87491fa3c09ad53275369d",
      "9b56cc7217dd4d0e8655e2b8cea99d2b",
      "5ba9bd8b97c94d31bee1e1a727348bd6",
      "5691af3a4c03488c9411732d5dbb4602",
      "324284bc71a140ce91ae3c208468ebd6",
      "fab4ba7d5ffd4191a69fdf82eae4603f",
      "124dd4de28f643bf9367eb4d9fb17204",
      "5e032fa1c328422aa15b553325e3a810",
      "0ca7af50cb73447fb1b9b7dd453f1e70",
      "6adc2def70864b62842e56b556af2540",
      "c06a7b1b934f4abba0d132850473fe92",
      "f4c18b8fee50413dbeb63c5d437a04be",
      "02c04c26bf984aecab65a7ce211a56f6",
      "fcc483b359e9499a97e5b609b10d4f71",
      "68c9fcfce4734c8e86aba9c930a39f53",
      "f3dcb7aab51d456cbe7835553867392c",
      "9aebed182d8e437f92f18c59bcf0effe",
      "58bf5a3dc0414f3585eebf84f49a595a",
      "cdcde258dafa4719ac8f39f1be1e1ef9",
      "9bb64b41a4d149319190750a42018cee",
      "fbc441e5989b4c5aadf22ff1994a44ae",
      "cac55ed1f32f43b493b76f0eb20eced4",
      "55500e4b07e34cbfac740505f85db711",
      "dd50dfad8b2e4c2cb888ca1cfbd1a341",
      "41da7342a4764f9bbbf38c27b7ef97d6",
      "b624ed59044744c5b3050b791bc3051c",
      "8a23af41efd648439b5ad7191a6e5a1a",
      "de845b2b3fcd46a6a407a3125529a4a8",
      "1f5fdb0ece6742dc8b91c2be24ea5037",
      "75fe327382724e229485c1a45cd51c10",
      "77fdced73e894393b68c365a9a08ee51",
      "88c445a738f04cb8977c39243e730c97",
      "df3c59d8b3084a7a814b8f7d445a7db3",
      "78892226723f4ba0aff56bb40addd649",
      "6c7fed0262a74fcebd3f85a69241de70",
      "31227b377e0d4b78b4fe3f99a4d90a46",
      "0f61fb8d935d447c95b004f8f7d24744",
      "2c9acb73c1384f1793d0b2e5fd390ed9",
      "53a3ea7cfca94737ae0de9de9fb7a694",
      "04a6745912654f6480df15b9a67ab0a3",
      "5778d51b8e4b49c999c88bc22382642e",
      "1ccb02506d0a41baa9c9b8223c36404d",
      "07ee5dea5ebb40418f205ac34e562683",
      "d48cfcab6ce84a0f81b910305fc8a73a",
      "95c83d713443463c96b77cff09e5a594",
      "85d05c95e2ea4e6598040b69c72e7848",
      "04ecd55ecc834c46a739317a85da886d",
      "f75d868048d54fcba17321fcae03d645"
     ]
    },
    "collapsed": true,
    "id": "-Rzf9DeqvMis",
    "outputId": "4c5baacf-664e-4dcc-c25b-d4562907e03d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474354289e6140a48e92ec55889bd19b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78813c78dec3495e90b6a7f83aa56322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/85.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd1a33d099c466f8c6131403b59be4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/936k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d166eacb3824d5ebc8538aae895129e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/1.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c302b2b224474de3a106c23715313195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/182822 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a9b16aa34a4199ace16a6bd441f293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/6150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324284bc71a140ce91ae3c208468ebd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/4183 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3dcb7aab51d456cbe7835553867392c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/182822 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a23af41efd648439b5ad7191a6e5a1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9acb73c1384f1793d0b2e5fd390ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4183 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"openlifescienceai/medmcqa\")\n",
    "\n",
    "# Apply formatting\n",
    "dataset = dataset.map(format_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1Y2856P-PtZV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Y2856P-PtZV",
    "outputId": "b1e819c6-a1f3-4786-92aa-c165709861e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Question: Which vitamin is supplied from only animal source:\n",
      "A. Vitamin C\n",
      "B. Vitamin B7\n",
      "C. Vitamin B12\n",
      "D. Vitamin D\n",
      "<|assistant|>\n",
      "Answer: C. Vitamin B12\n",
      "Explanation: Ans. (c) Vitamin B12 Ref: Harrison's 19th ed. P 640* Vitamin B12 (Cobalamin) is synthesized solely by microorganisms.* In humans, the only source for humans is food of animal origin, e.g., meat, fish, and dairy products.* Vegetables, fruits, and other foods of nonanimal origin doesn't contain Vitamin B12 .* Daily requirements of vitamin Bp is about 1-3 pg. Body stores are of the order of 2-3 mg, sufficient for 3-4 years if supplies are completely cut off.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'e3d3c4e1-4fb2-45e7-9f88-247cc8f373b3',\n",
       " 'question': 'Which vitamin is supplied from only animal source:',\n",
       " 'opa': 'Vitamin C',\n",
       " 'opb': 'Vitamin B7',\n",
       " 'opc': 'Vitamin B12',\n",
       " 'opd': 'Vitamin D',\n",
       " 'cop': 2,\n",
       " 'choice_type': 'single',\n",
       " 'exp': \"Ans. (c) Vitamin B12 Ref: Harrison's 19th ed. P 640* Vitamin B12 (Cobalamin) is synthesized solely by microorganisms.* In humans, the only source for humans is food of animal origin, e.g., meat, fish, and dairy products.* Vegetables, fruits, and other foods of nonanimal origin doesn't contain Vitamin B12 .* Daily requirements of vitamin Bp is about 1-3 pg. Body stores are of the order of 2-3 mg, sufficient for 3-4 years if supplies are completely cut off.\",\n",
       " 'subject_name': 'Biochemistry',\n",
       " 'topic_name': 'Vitamins and Minerals',\n",
       " 'text': \"<|user|>\\nQuestion: Which vitamin is supplied from only animal source:\\nA. Vitamin C\\nB. Vitamin B7\\nC. Vitamin B12\\nD. Vitamin D\\n<|assistant|>\\nAnswer: C. Vitamin B12\\nExplanation: Ans. (c) Vitamin B12 Ref: Harrison's 19th ed. P 640* Vitamin B12 (Cobalamin) is synthesized solely by microorganisms.* In humans, the only source for humans is food of animal origin, e.g., meat, fish, and dairy products.* Vegetables, fruits, and other foods of nonanimal origin doesn't contain Vitamin B12 .* Daily requirements of vitamin Bp is about 1-3 pg. Body stores are of the order of 2-3 mg, sufficient for 3-4 years if supplies are completely cut off.\"}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataset['train'][1]['text'])\n",
    "dataset['train'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5IvEwqfnyVbE",
   "metadata": {
    "id": "5IvEwqfnyVbE"
   },
   "source": [
    "## Tokenizing the dataset - converting text into numbers the model understands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0gUwCFf4yYl_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "556535ad1bf946c6b3276cbaa88e800a",
      "b316c22e1b4643f085598fb02f416c1b",
      "a071248e044b40f9b9b4150b4f5225b4",
      "c3662f0f58e0436da687345667a120d3",
      "66079af5d7f149d6a3cc83fddc83081e",
      "c6be6689f0174159ba8924a2fadee68d",
      "ea3da8048ba143609a49e282b45b9e1d",
      "9da2ebcc940f41ab8f9f3592b3bdd3d7",
      "75fb31dba8c7416d90ec2a3cd4a08554",
      "7509c055308142ac8bbcdf528844882f",
      "80153a4c049a4161b74e2584874ca18f",
      "648f1d430d1c45e4b2c0a35a3cc72f40",
      "31dce607b99d42ae8cbf56ae7e197339",
      "b939db4662074a01a44277b0be5f3d48",
      "b7130968a60e4cf9ac30ac734da006b1",
      "183ce8c009e64b159bd2e8cbb7f7d06a",
      "be3e1ebb8294490581a162a0696160fd",
      "f036832424e9437ab450cc6a11d87d2c",
      "93d76c2b26e949b7b55a99e7082d1cf5",
      "f0f0de1f1a324416a0a134385b39cc7d",
      "aa8acb3f01f046c4a3617a093664a1b1",
      "5837ccb0d1b446d79528625a1e29dbb7",
      "6841635a697f40adb60825d3001521dd",
      "55ec52fe277448b582d8522747bc22d0",
      "491cbce00fc54fe69ec883f8fa88b838",
      "3b949e1d7d3345129522db81848d03ff",
      "5cadef4d3fb0493696412c0648cb7829",
      "1cc1296ec15e4730958d6db5a6b95d5a",
      "3fd54e2b042b47aeb8633d4c23a548ca",
      "89d8519511974782a251816314e78b39",
      "fe41becc801f455d92b8bee1d50bfcfd",
      "25e3e6b77e32449881065b3ef3dcbd61",
      "835e62a4afac46378f8f8addcb3eeead"
     ]
    },
    "id": "0gUwCFf4yYl_",
    "outputId": "e231e361-b879-42de-a73b-cb0d76be86f8"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556535ad1bf946c6b3276cbaa88e800a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/182822 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "648f1d430d1c45e4b2c0a35a3cc72f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6150 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6841635a697f40adb60825d3001521dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4183 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set your max length (LLaMA3 default is 2048 tokens)\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "# Tokenize using the tokenizer from Unsloth\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(\n",
    "        example[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding=False,  # Let batching handle padding\n",
    "        return_tensors=None,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "# Then tokenize\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_d9LAzTnzLN-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "_d9LAzTnzLN-",
    "outputId": "bb778626-2452-4ca1-e410-40d563f0fb0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'e7f023ea-2147-47d3-9f2a-61fb60a900be',\n",
       " 'question': 'Which of these drugs is an antidote for fibrinolytic therapy?',\n",
       " 'opa': 'Epsilon aminocaproic acid',\n",
       " 'opb': 'Protamine',\n",
       " 'opc': 'Heparin',\n",
       " 'opd': 'Streptokinase',\n",
       " 'cop': 0,\n",
       " 'choice_type': 'single',\n",
       " 'exp': 'Answer- A. Epsilon aminocaproic acidEpsilon aminocaproic acid is an antidote for fibrinolytic therapy. Epsilon-aminocaproic qcid is a synthetic inhibitor of theplasmin-plasminogen system. It is the only potent antifibrinolylic agent, which is commercially available.\"Aminocaproic acid is a lysine analog that competes for lysine binding sites on plasminogen and plasmin, blocking theinteraction of plasmin with fibrin.Fibrinolytic overdose - Epsilon Amino Caproic Acid (EACA)',\n",
       " 'subject_name': 'Pharmacology',\n",
       " 'topic_name': None,\n",
       " 'text': '<|user|>\\nQuestion: Which of these drugs is an antidote for fibrinolytic therapy?\\nA. Epsilon aminocaproic acid\\nB. Protamine\\nC. Heparin\\nD. Streptokinase\\n<|assistant|>\\nAnswer: A. Epsilon aminocaproic acid\\nExplanation: Answer- A. Epsilon aminocaproic acidEpsilon aminocaproic acid is an antidote for fibrinolytic therapy. Epsilon-aminocaproic qcid is a synthetic inhibitor of theplasmin-plasminogen system. It is the only potent antifibrinolylic agent, which is commercially available.\"Aminocaproic acid is a lysine analog that competes for lysine binding sites on plasminogen and plasmin, blocking theinteraction of plasmin with fibrin.Fibrinolytic overdose - Epsilon Amino Caproic Acid (EACA)',\n",
       " 'input_ids': [128000,\n",
       "  27,\n",
       "  91,\n",
       "  882,\n",
       "  91,\n",
       "  397,\n",
       "  14924,\n",
       "  25,\n",
       "  16299,\n",
       "  315,\n",
       "  1521,\n",
       "  11217,\n",
       "  374,\n",
       "  459,\n",
       "  90687,\n",
       "  1295,\n",
       "  369,\n",
       "  95235,\n",
       "  258,\n",
       "  5849,\n",
       "  29150,\n",
       "  15419,\n",
       "  5380,\n",
       "  32,\n",
       "  13,\n",
       "  469,\n",
       "  60992,\n",
       "  264,\n",
       "  1083,\n",
       "  511,\n",
       "  59948,\n",
       "  292,\n",
       "  13935,\n",
       "  198,\n",
       "  33,\n",
       "  13,\n",
       "  11970,\n",
       "  20588,\n",
       "  198,\n",
       "  34,\n",
       "  13,\n",
       "  473,\n",
       "  11845,\n",
       "  258,\n",
       "  198,\n",
       "  35,\n",
       "  13,\n",
       "  36772,\n",
       "  418,\n",
       "  79117,\n",
       "  521,\n",
       "  198,\n",
       "  27,\n",
       "  91,\n",
       "  78191,\n",
       "  91,\n",
       "  397,\n",
       "  16533,\n",
       "  25,\n",
       "  362,\n",
       "  13,\n",
       "  469,\n",
       "  60992,\n",
       "  264,\n",
       "  1083,\n",
       "  511,\n",
       "  59948,\n",
       "  292,\n",
       "  13935,\n",
       "  198,\n",
       "  70869,\n",
       "  25,\n",
       "  22559,\n",
       "  12,\n",
       "  362,\n",
       "  13,\n",
       "  469,\n",
       "  60992,\n",
       "  264,\n",
       "  1083,\n",
       "  511,\n",
       "  59948,\n",
       "  292,\n",
       "  13935,\n",
       "  36,\n",
       "  60992,\n",
       "  264,\n",
       "  1083,\n",
       "  511,\n",
       "  59948,\n",
       "  292,\n",
       "  13935,\n",
       "  374,\n",
       "  459,\n",
       "  90687,\n",
       "  1295,\n",
       "  369,\n",
       "  95235,\n",
       "  258,\n",
       "  5849,\n",
       "  29150,\n",
       "  15419,\n",
       "  13,\n",
       "  469,\n",
       "  60992,\n",
       "  12,\n",
       "  8778,\n",
       "  511,\n",
       "  59948,\n",
       "  292,\n",
       "  2874,\n",
       "  21200,\n",
       "  374,\n",
       "  264,\n",
       "  28367,\n",
       "  70785,\n",
       "  315,\n",
       "  279,\n",
       "  501,\n",
       "  300,\n",
       "  1083,\n",
       "  33207,\n",
       "  300,\n",
       "  1083,\n",
       "  11968,\n",
       "  1887,\n",
       "  13,\n",
       "  1102,\n",
       "  374,\n",
       "  279,\n",
       "  1193,\n",
       "  36875,\n",
       "  3276,\n",
       "  333,\n",
       "  10892,\n",
       "  258,\n",
       "  5849,\n",
       "  416,\n",
       "  8479,\n",
       "  11,\n",
       "  902,\n",
       "  374,\n",
       "  54453,\n",
       "  2561,\n",
       "  1210,\n",
       "  32,\n",
       "  1083,\n",
       "  511,\n",
       "  59948,\n",
       "  292,\n",
       "  13935,\n",
       "  374,\n",
       "  264,\n",
       "  84495,\n",
       "  483,\n",
       "  24291,\n",
       "  430,\n",
       "  4634,\n",
       "  288,\n",
       "  369,\n",
       "  84495,\n",
       "  483,\n",
       "  11212,\n",
       "  6732,\n",
       "  389,\n",
       "  628,\n",
       "  300,\n",
       "  1083,\n",
       "  11968,\n",
       "  323,\n",
       "  628,\n",
       "  300,\n",
       "  1083,\n",
       "  11,\n",
       "  22978,\n",
       "  279,\n",
       "  69175,\n",
       "  315,\n",
       "  628,\n",
       "  300,\n",
       "  1083,\n",
       "  449,\n",
       "  95235,\n",
       "  258,\n",
       "  1006,\n",
       "  10892,\n",
       "  258,\n",
       "  5849,\n",
       "  29150,\n",
       "  60553,\n",
       "  482,\n",
       "  469,\n",
       "  60992,\n",
       "  362,\n",
       "  32924,\n",
       "  8171,\n",
       "  299,\n",
       "  292,\n",
       "  50234,\n",
       "  320,\n",
       "  36,\n",
       "  63638,\n",
       "  8],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset[\"validation\"][100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uJGwMSQQk5-H",
   "metadata": {
    "id": "uJGwMSQQk5-H"
   },
   "source": [
    "# Finding The Optimized Sequence for training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jGLzxE7Fmkq_",
   "metadata": {
    "id": "jGLzxE7Fmkq_"
   },
   "source": [
    "## Training Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15XbXxdklvkI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 686
    },
    "id": "15XbXxdklvkI",
    "outputId": "a7487b0f-7961-42eb-a504-95a89badf35b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing samples: 100%|██████████| 182822/182822 [02:46<00:00, 1096.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔢 Token Length Statistics:\n",
      "Min: 44 tokens\n",
      "Max: 5394 tokens\n",
      "Mean: 184.33 tokens\n",
      "90th Percentile: 333 tokens\n",
      "95th Percentile: 435 tokens\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "\n",
    "# ⚠️ Replace with your dataset if needed\n",
    "df = tokenized_dataset[\"train\"]  # assumes HuggingFace Dataset format\n",
    "\n",
    "# 🧮 Collect token lengths\n",
    "token_lengths = []\n",
    "# Iterate over the 'df' variable which holds the dataset split, not the string 'dataset'\n",
    "for example in tqdm(df, desc=\"Tokenizing samples\"):\n",
    "    text = example[\"text\"]\n",
    "    tokens = tokenizer(text, truncation=False)[\"input_ids\"]\n",
    "    token_lengths.append(len(tokens))\n",
    "\n",
    "# 📊 Basic statistics\n",
    "min_len = np.min(token_lengths)\n",
    "max_len = np.max(token_lengths)\n",
    "mean_len = np.mean(token_lengths)\n",
    "p90 = np.percentile(token_lengths, 90)\n",
    "p95 = np.percentile(token_lengths, 95)\n",
    "\n",
    "print(f\"🔢 Token Length Statistics:\")\n",
    "print(f\"Min: {min_len} tokens\")\n",
    "print(f\"Max: {max_len} tokens\")\n",
    "print(f\"Mean: {mean_len:.2f} tokens\")\n",
    "print(f\"90th Percentile: {p90:.0f} tokens\")\n",
    "print(f\"95th Percentile: {p95:.0f} tokens\")\n",
    "\n",
    "# 📈 Plot the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(token_lengths, bins=50, kde=True, color=\"teal\")\n",
    "plt.title(\"Distribution of Token Sequence Lengths\")\n",
    "plt.xlabel(\"Number of Tokens per Sample\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1xbFzdQhmqp_",
   "metadata": {
    "id": "1xbFzdQhmqp_"
   },
   "source": [
    "## Validation Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PRTl8MeimuaI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 686
    },
    "id": "PRTl8MeimuaI",
    "outputId": "9c2e1739-61c4-4657-b45b-d361e9f0c6c0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing samples: 100%|██████████| 4183/4183 [00:03<00:00, 1278.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔢 Token Length Statistics:\n",
      "Min: 44 tokens\n",
      "Max: 1020 tokens\n",
      "Mean: 140.61 tokens\n",
      "90th Percentile: 263 tokens\n",
      "95th Percentile: 318 tokens\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ⚠️ Replace with your dataset if needed\n",
    "df = tokenized_dataset[\"validation\"]  # assumes HuggingFace Dataset format\n",
    "\n",
    "# 🧮 Collect token lengths\n",
    "token_lengths = []\n",
    "# Iterate over the 'df' variable which holds the dataset split, not the string 'dataset'\n",
    "for example in tqdm(df, desc=\"Tokenizing samples\"):\n",
    "    text = example[\"text\"]\n",
    "    tokens = tokenizer(text, truncation=False)[\"input_ids\"]\n",
    "    token_lengths.append(len(tokens))\n",
    "\n",
    "# 📊 Basic statistics\n",
    "min_len = np.min(token_lengths)\n",
    "max_len = np.max(token_lengths)\n",
    "mean_len = np.mean(token_lengths)\n",
    "p90 = np.percentile(token_lengths, 90)\n",
    "p95 = np.percentile(token_lengths, 95)\n",
    "\n",
    "print(f\"🔢 Token Length Statistics:\")\n",
    "print(f\"Min: {min_len} tokens\")\n",
    "print(f\"Max: {max_len} tokens\")\n",
    "print(f\"Mean: {mean_len:.2f} tokens\")\n",
    "print(f\"90th Percentile: {p90:.0f} tokens\")\n",
    "print(f\"95th Percentile: {p95:.0f} tokens\")\n",
    "\n",
    "# 📈 Plot the distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(token_lengths, bins=50, kde=True, color=\"teal\")\n",
    "plt.title(\"Distribution of Token Sequence Lengths\")\n",
    "plt.xlabel(\"Number of Tokens per Sample\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KQdtzBB1Ozpk",
   "metadata": {
    "id": "KQdtzBB1Ozpk"
   },
   "source": [
    "# Setup Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "B3FP2S6ZQ52i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3FP2S6ZQ52i",
    "outputId": "b1801443-8626-4d4b-b663-16414b5e08fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers==4.51.3 in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.33.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (2.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (2024.11.6)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.51.3) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (4.14.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.51.3) (2025.6.15)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.51.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tlGSuoQfgN__",
   "metadata": {
    "id": "tlGSuoQfgN__"
   },
   "source": [
    "# Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JXJdEHH5gWQn",
   "metadata": {
    "id": "JXJdEHH5gWQn"
   },
   "outputs": [],
   "source": [
    "# 7. Model Fine-Tuning (SFTTrainer setup)\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, DataCollatorForSeq2Seq, EarlyStoppingCallback\n",
    "from unsloth import is_bfloat16_supported\n",
    "from peft import LoraConfig\n",
    "\n",
    "# 🔧 Sequence length optimized based on your dataset (most under 256)\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "# 🧠 LoRA Configuration (with slightly higher dropout to reduce overfitting)\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    target_modules=[\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "        \"embed_tokens\", \"lm_head\",\n",
    "    ],\n",
    "    bias=\"none\",\n",
    "    lora_dropout=0.1,  # 🔺 Improved generalization\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# 🏋️ Training Arguments (optimized for A100 or L4 - 24GB VRAM)\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=64,             # 🔺 Increased batch, no gradient accumulation\n",
    "    gradient_accumulation_steps=1,              # 🔺 Fixes Unsloth warning\n",
    "    warmup_steps=5,\n",
    "    max_steps=1000,                             # 🔺 More steps to improve performance\n",
    "    learning_rate=2e-5,\n",
    "    fp16=False,                                 # LLaMA 3 is bfloat16-native\n",
    "    bf16=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=50,\n",
    "    optim=\"adamw_8bit\",\n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    seed=3407,\n",
    "    output_dir=\"outputs\",\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "# 🧪 Final Trainer Setup\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=MAX_LENGTH,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer),\n",
    "    dataset_num_proc=2,\n",
    "    packing=True,\n",
    "    peft_config=lora_config,\n",
    "    args=training_args,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DCrrdCzOzYd5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 841
    },
    "id": "DCrrdCzOzYd5",
    "outputId": "0e640bac-8eb4-41a1-8b63-fce0f1714eb9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 182,822 | Num Epochs = 1 | Total steps = 1,000\n",
      "O^O/ \\_/ \\    Batch size per device = 64 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (64 x 1 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 41,943,040/8,000,000,000 (0.52% trained)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 1:44:33, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.752900</td>\n",
       "      <td>1.666577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.544200</td>\n",
       "      <td>1.583727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.489000</td>\n",
       "      <td>1.575733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.487800</td>\n",
       "      <td>1.572178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>1.481600</td>\n",
       "      <td>1.568117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.465500</td>\n",
       "      <td>1.565383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>1.466400</td>\n",
       "      <td>1.562213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.468100</td>\n",
       "      <td>1.563637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>1.466400</td>\n",
       "      <td>1.560278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.469400</td>\n",
       "      <td>1.557565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>1.461500</td>\n",
       "      <td>1.557065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>1.454700</td>\n",
       "      <td>1.559148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>1.458600</td>\n",
       "      <td>1.555523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>1.461500</td>\n",
       "      <td>1.552701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>1.452900</td>\n",
       "      <td>1.554481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>1.446800</td>\n",
       "      <td>1.553508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>1.457500</td>\n",
       "      <td>1.551273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>1.445700</td>\n",
       "      <td>1.551989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>1.442900</td>\n",
       "      <td>1.551684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.443000</td>\n",
       "      <td>1.551490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1000, training_loss=1.480826072692871, metrics={'train_runtime': 6288.9019, 'train_samples_per_second': 10.177, 'train_steps_per_second': 0.159, 'total_flos': 7.41887283560448e+17, 'train_loss': 1.480826072692871})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7wvQbQ1mj6Jp",
   "metadata": {
    "id": "7wvQbQ1mj6Jp"
   },
   "source": [
    "# Evalution Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dXACPKqeg1R",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7dXACPKqeg1R",
    "outputId": "e4bd9e47-40f1-404b-a415-cc9f7f2ce021"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6665765047073364, 'eval_runtime': 116.6237, 'eval_samples_per_second': 35.867, 'eval_steps_per_second': 4.485, 'epoch': 0.01750087504375219, 'step': 50}\n",
      "{'eval_loss': 1.5837268829345703, 'eval_runtime': 113.6261, 'eval_samples_per_second': 36.814, 'eval_steps_per_second': 4.603, 'epoch': 0.03500175008750438, 'step': 100}\n",
      "{'eval_loss': 1.5757334232330322, 'eval_runtime': 113.7234, 'eval_samples_per_second': 36.782, 'eval_steps_per_second': 4.599, 'epoch': 0.052502625131256565, 'step': 150}\n",
      "{'eval_loss': 1.572177767753601, 'eval_runtime': 113.5366, 'eval_samples_per_second': 36.843, 'eval_steps_per_second': 4.606, 'epoch': 0.07000350017500875, 'step': 200}\n",
      "{'eval_loss': 1.5681166648864746, 'eval_runtime': 113.5589, 'eval_samples_per_second': 36.836, 'eval_steps_per_second': 4.606, 'epoch': 0.08750437521876094, 'step': 250}\n",
      "{'eval_loss': 1.565382719039917, 'eval_runtime': 113.5476, 'eval_samples_per_second': 36.839, 'eval_steps_per_second': 4.606, 'epoch': 0.10500525026251313, 'step': 300}\n",
      "{'eval_loss': 1.562212586402893, 'eval_runtime': 113.7432, 'eval_samples_per_second': 36.776, 'eval_steps_per_second': 4.598, 'epoch': 0.12250612530626531, 'step': 350}\n",
      "{'eval_loss': 1.563637137413025, 'eval_runtime': 113.6289, 'eval_samples_per_second': 36.813, 'eval_steps_per_second': 4.603, 'epoch': 0.1400070003500175, 'step': 400}\n",
      "{'eval_loss': 1.5602777004241943, 'eval_runtime': 113.6773, 'eval_samples_per_second': 36.797, 'eval_steps_per_second': 4.601, 'epoch': 0.15750787539376968, 'step': 450}\n",
      "{'eval_loss': 1.5575650930404663, 'eval_runtime': 113.8494, 'eval_samples_per_second': 36.742, 'eval_steps_per_second': 4.594, 'epoch': 0.17500875043752187, 'step': 500}\n",
      "{'eval_loss': 1.5570646524429321, 'eval_runtime': 113.6562, 'eval_samples_per_second': 36.804, 'eval_steps_per_second': 4.602, 'epoch': 0.19250962548127407, 'step': 550}\n",
      "{'eval_loss': 1.5591481924057007, 'eval_runtime': 113.673, 'eval_samples_per_second': 36.799, 'eval_steps_per_second': 4.601, 'epoch': 0.21001050052502626, 'step': 600}\n",
      "{'eval_loss': 1.5555225610733032, 'eval_runtime': 113.6394, 'eval_samples_per_second': 36.809, 'eval_steps_per_second': 4.602, 'epoch': 0.22751137556877843, 'step': 650}\n",
      "{'eval_loss': 1.5527013540267944, 'eval_runtime': 113.6489, 'eval_samples_per_second': 36.806, 'eval_steps_per_second': 4.602, 'epoch': 0.24501225061253062, 'step': 700}\n",
      "{'eval_loss': 1.5544809103012085, 'eval_runtime': 113.6729, 'eval_samples_per_second': 36.799, 'eval_steps_per_second': 4.601, 'epoch': 0.2625131256562828, 'step': 750}\n",
      "{'eval_loss': 1.553507685661316, 'eval_runtime': 113.7708, 'eval_samples_per_second': 36.767, 'eval_steps_per_second': 4.597, 'epoch': 0.280014000700035, 'step': 800}\n",
      "{'eval_loss': 1.5512726306915283, 'eval_runtime': 113.6972, 'eval_samples_per_second': 36.791, 'eval_steps_per_second': 4.6, 'epoch': 0.2975148757437872, 'step': 850}\n",
      "{'eval_loss': 1.5519890785217285, 'eval_runtime': 113.7044, 'eval_samples_per_second': 36.788, 'eval_steps_per_second': 4.6, 'epoch': 0.31501575078753935, 'step': 900}\n",
      "{'eval_loss': 1.551684021949768, 'eval_runtime': 113.6464, 'eval_samples_per_second': 36.807, 'eval_steps_per_second': 4.602, 'epoch': 0.33251662583129155, 'step': 950}\n",
      "{'eval_loss': 1.5514897108078003, 'eval_runtime': 113.6325, 'eval_samples_per_second': 36.812, 'eval_steps_per_second': 4.603, 'epoch': 0.35001750087504374, 'step': 1000}\n"
     ]
    }
   ],
   "source": [
    "for entry in trainer.state.log_history:\n",
    "    if \"eval_loss\" in entry:\n",
    "        print(entry)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HyKlxLlmn_QW",
   "metadata": {
    "id": "HyKlxLlmn_QW"
   },
   "source": [
    "## Visulization Evalution Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JS4b77a6n-hg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "JS4b77a6n-hg",
    "outputId": "e0b89f7e-c86b-4d30-f522-7492e2531a80"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Extract training and evaluation loss\n",
    "logs = trainer.state.log_history\n",
    "train_steps, train_loss = [], []\n",
    "eval_steps, eval_loss = [], []\n",
    "\n",
    "for entry in logs:\n",
    "    if \"loss\" in entry and \"step\" in entry:\n",
    "        train_steps.append(entry[\"step\"])\n",
    "        train_loss.append(entry[\"loss\"])\n",
    "    if \"eval_loss\" in entry and \"step\" in entry:\n",
    "        eval_steps.append(entry[\"step\"])\n",
    "        eval_loss.append(entry[\"eval_loss\"])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_steps, train_loss, label=\"Training Loss\", color=\"red\")\n",
    "plt.plot(eval_steps, eval_loss, label=\"Validation Loss\", color=\"blue\", marker=\"o\", linestyle=\"-\", markersize=8)\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss Curves\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Format y-axis ticks to show 3 decimal places\n",
    "plt.gca().yaxis.set_major_formatter(ticker.FormatStrFormatter('%.3f'))\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "VGosjQ9GhMdI",
   "metadata": {
    "id": "VGosjQ9GhMdI"
   },
   "source": [
    "# Saving The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "HHHWgVB4iANK",
   "metadata": {
    "id": "HHHWgVB4iANK"
   },
   "source": [
    "## Logging in Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mH_F-wsHhPRO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "b542d8c568e943fb8d1f68e4ca43c7c4",
      "0c0d4ef44c344b89b2b2e6289aa06c7b",
      "12ba92b05e16496ca5518efbb8debba6",
      "3eb92edc1f2443bfafdd9871359f8160",
      "b7f92e6245a74b67bc18686fdc0a99d1",
      "58ca12610eaa46b3a9a63c7a71ede120",
      "9f099626607d495697df6de5ac22853e",
      "460d92b3eb66443ebee3c12ae8b1c6dd",
      "3d36ac1b533f4cd68c58c3e537e98c9c",
      "46edd59c019f46e18d31b1dbc6c391e9",
      "783bd5d0d96c47dc8e39d95140503fe9",
      "d9ea2e7ad207408797ea812125ed1905",
      "e693c84ba5554d79a33a82f0f2455a87",
      "fe72cc882bbf44eab7568be87cba1502",
      "821fdff2a082413c9c2dedf81f6185d3",
      "011ce3b860034f9da86f2eaa22bd278c",
      "ebd4e212ca2441b3a4e5280bac30c720",
      "cb6263d6af9340ab8eb6c275791b8a35",
      "a0914b220dc04d389f4f382ef8a6eb85",
      "80c07d6da3ea43e2a275bc2939f57f3d"
     ]
    },
    "id": "mH_F-wsHhPRO",
    "outputId": "8751e68f-3173-4d98-93eb-73c203b9e975"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b542d8c568e943fb8d1f68e4ca43c7c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wvUw38tUiHeI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvUw38tUiHeI",
    "outputId": "b7041bc3-ab4d-40cd-9671-d3049a2c7f46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('llama3-medmcqa-AmirKhier/tokenizer_config.json',\n",
       " 'llama3-medmcqa-AmirKhier/special_tokens_map.json',\n",
       " 'llama3-medmcqa-AmirKhier/tokenizer.json')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"YOUR_MODEL\")\n",
    "tokenizer.save_pretrained(\"YOUR_MODEL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XRo_aUjYiRde",
   "metadata": {
    "id": "XRo_aUjYiRde"
   },
   "source": [
    "## Pushing to My Hugging Face Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9g-hAe3IigE3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9g-hAe3IigE3",
    "outputId": "1341e6e4-5dde-44d3-9aef-714fa2473461"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Your Username : Amir32432\n"
     ]
    }
   ],
   "source": [
    "username = input(\"Enter Your Username : \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kVxROhXjiXXW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194,
     "referenced_widgets": [
      "c8587daeac164c6f8fef7ddbc143d885",
      "0621728317154823b36763b3b17de520",
      "5e86fe3c96a24dd89bb6f3c3323f9c76",
      "c2e5342f2398464da91a6e7b685fc8ca",
      "5563d638f31a4f448d602fd12bda7084",
      "cbdf579e5bd341848d14265f381df52b",
      "4bb001b0a59b4b9887ed33e3bebc9cd2",
      "33d87f301876489d9fe242988d78b9e3",
      "80c8a5105d8849c5a4d10547b923aac3",
      "c580c640c0d24a868873cb61d4aa021a",
      "df1b26b78521487ca8bc84a931f3cd8c",
      "38549cc015164616aa9368b326c18e7c",
      "cde83d9de0bf4b0e98313526c987585f",
      "c6c76c19af2b40069fb9264b5a48b3e9",
      "3846b19474654e17887829d64ecb71b4",
      "681f7a1eb17d4ce883c8cabbf2c45cbf",
      "001cc058a36246fdbd58264d011c10d8",
      "4703793f67c54f3daa7e6921b13e1910",
      "f363185fb3e543408134780f2c2bcf93",
      "88665a3b21f942aa9a7f42d40348446a",
      "73c83578eedb4a249ff7a97a670d1281",
      "21556f321e73479d90d10c3247c76f90",
      "8ffe8ac1dc314afa960d12711766149c",
      "f60ff1f129dd4a1986d3804f427320c9",
      "08c0f52a12384f809b9b1a23522ea68f",
      "33f1044762734580b63ef28d7ef54b59",
      "9dd4b980ef9b4fc1ae9588cc19a5aa82",
      "dfe88b2924104f1f8ad311b686edbd53",
      "a15dc4ba15ec4a2db569f6340cab2d17",
      "1c8a80eca1684ecd8250e7bcea490dce",
      "9240e89e0d624e02aebbde0be720dfc8",
      "050a030593eb427d9011d089ab5de99f",
      "67a2d396c0004d47989c96aacc7a4d03",
      "70fc6b41006d446b90f07c3f3365f8fd",
      "5819bea4a46e460bbc50129e0f0e6e92",
      "587a2b21126f4da1bea5d31aaa0e25f0",
      "14c2d642357e437cb8f161cbe0041f7d",
      "30fbf1d62b51427bbccba7857f786e8d",
      "20b83ea4dab64ca1bff629edcab1acc6",
      "bc4eb8da9fbb406d908c7a38d2607cbf",
      "2cd1552842dd45dd9f0a48f62d9dfb32",
      "2e5056b31f5344f69fdab0b958040f35",
      "04ad27be041a45348f16602f92d12e8b",
      "9c485a84bd4b44b798647e8b99667524",
      "8e371b4ad3ac4939ae1d96461b377cd2",
      "de340fe3a2a24231bf8fcb9bd8f9aa14",
      "41ff65fb928e46a2bf40d7e21ecf3fb3",
      "b15cabc9db5844418c9126f4056725ef",
      "32358a8a80944cae877c1622f9a39788",
      "ace5dab020584985be58cdbacbc51cbd",
      "5e3da5dfeb9b42d3bea7aa84444f7b82",
      "18d7ad2408174daa9994804f86a8ff86",
      "14b78296c9824bbfa0ae01455989566b",
      "fac0d21ca99b49d3b956199de3a8a809",
      "486d4092bd824d23845abd06420ff572"
     ]
    },
    "id": "kVxROhXjiXXW",
    "outputId": "0a846157-c9ff-41cc-88d1-5be46162306e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8587daeac164c6f8fef7ddbc143d885",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38549cc015164616aa9368b326c18e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ffe8ac1dc314afa960d12711766149c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to https://huggingface.co/Amir32432/llama3-medmcqa-AmirKhier\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fc6b41006d446b90f07c3f3365f8fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e371b4ad3ac4939ae1d96461b377cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.push_to_hub(f\"{username}/MODEL\")\n",
    "tokenizer.push_to_hub(f\"{username}/MODEL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1VRm-BAyjKQ-",
   "metadata": {
    "id": "1VRm-BAyjKQ-"
   },
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "JkCW6QaSlX_t",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JkCW6QaSlX_t",
    "outputId": "fc75db7a-ed35-4bfd-9883-10b2401cbf62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The description you're likely referring to is the Eiffel Tower, which stands in the heart of the capital of France: Paris.  The Eiffel Tower is a famous iron lattice tower that serves as a symbol of the city and France itself.  Here's a description:\n",
      "\n",
      "The Eiffel Tower stands at an impressive height of 324 meters (1,063 feet) tall, making it one of the tallest structures in the world.  The tower has an octagonal shape and is comprised of four main pillars that meet at the top to form a platform.  The pillars are supported by a system of girders and\n"
     ]
    }
   ],
   "source": [
    "if False:\n",
    "    from unsloth import FastLanguageModel\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"YOUR_MODEL\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = load_in_4bit,\n",
    "    )\n",
    "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe a tall tower in the capital of France.\"},\n",
    "]\n",
    "inputs = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize = True,\n",
    "    add_generation_prompt = True, # Must add for generation\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
    "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "So9eA0sVkijX",
   "metadata": {
    "id": "So9eA0sVkijX"
   },
   "source": [
    "# Testing The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qXF_OT45tMxv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXF_OT45tMxv",
    "outputId": "2e73be69-ed00-4559-c425-484ce978fb8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Prompt 1 ---\n",
      "📝 True of umbilical hernia -\n",
      "\n",
      "🤖 True of umbilical hernia - a condition in which a part of the intestine protrudes through an opening in the abdominal wall, typically in infants. It's usually harmless and may not cause any symptoms. If symptoms do occur, they may include a visible bulge or lump in the navel area, pain or discomfort when the baby moves or coughs, and a feeling of the bulge getting bigger when the baby cries or strains.\n",
      "In some cases, umbilical hernias may cause complications, such as bowel obstruction or strangulation, which can be serious and require immediate medical attention. Treatment for umbilical hernia in infants usually involves monitoring the condition, and in some cases, surgery may be necessary to repair the hernia.\n",
      "In adults, umbilical hernias are more common and may be caused by various factors, such as obesity, pregnancy, or previous abdominal surgery. Symptoms may include a visible bulge or lump in the navel area, pain or discomfort, and difficulty breathing. Treatment for umbilical\n",
      "\n",
      "\n",
      "--- Prompt 2 ---\n",
      "📝 Failure rate of Pomeroy's method of tubal ligation is ?\n",
      "\n",
      "🤖 Failure rate of Pomeroy's method of tubal ligation is??\n",
      "A. 1-2%\n",
      "B. 1-3%\n",
      "C. 3-5%\n",
      "D. Pomeroy's method is a highly effective method with a failure rate of less than 1%.\n",
      "Answer is: D\n",
      "Explanation: Pomeroy's method is a highly effective method with a failure rate of less than 1%.Pomeroy's method is a technique used in tubal ligation. It is one of the most commonly used methods for permanent birth control. The technique involves cutting the fallopian tube in a loop, pulling the loop through the tube, and then tying the loop with a thread. This prevents the egg from being released from the ovary and fertilized. The failure rate of Pomeroy's method of tubal ligation is less than 1%. This means that less than 1% of women who undergo this procedure may become pregnant in the future. The high effectiveness of Pomeroy's method is due to its precise technique\n",
      "\n",
      "\n",
      "--- Prompt 3 ---\n",
      "📝 Tumor NOT commonly seen in first decade of life?\n",
      "\n",
      "🤖 Tumor NOT commonly seen in first decade of life? A. Neuroblastoma B. Rhabdomyosarcoma C. Hepatoblastoma D. Lymphoblastoma\n",
      "Answer: D\n",
      "Explanation: Lymphoblastoma is not commonly seen in the first decade of life. Neuroblastoma, Rhabdomyosarcoma, and Hepatoblastoma are commonly seen in the first decade of life. Neuroblastoma is a tumor of the sympathetic nervous system, usually presenting as an abdominal mass. Rhabdomyosarcoma is a tumor of the muscles, usually presenting as a soft tissue mass in the head and neck region. Hepatoblastoma is a tumor of the liver, usually presenting as an abdominal mass. Lymphoblastoma is a tumor of the lymphoid system, usually presenting as lymphadenopathy. It is commonly seen in the second decade of life. Therefore, the correct answer is D. Lymphoblastoma. REF: Robbins Pathology 9th edition\n",
      "\n",
      "\n",
      "--- Prompt 4 ---\n",
      "📝 Straight sinus is formed by?\n",
      "\n",
      "🤖 Straight sinus is formed by? (a) Left transverse sinus (b) Right transverse sinus (c) Left sigmoid sinus (d) Left occipital sinus\n",
      "Answer is: b\n",
      "Step 1:  To answer this question, we need to recall the anatomy of the venous sinuses in the brain.\n",
      "Step 2:  The straight sinus is a small venous structure located in the posterior part of the cranium.\n",
      "Step 3:  It is formed by the confluence of the two transverse sinuses, which are located on either side of the midline.\n",
      "Step 4:  The straight sinus receives blood from the transverse sinuses and drains it into the confluence of the sinuses, which is located in the falx cerebri.\n",
      "Step 5:  Therefore, the straight sinus is formed by the right transverse sinus.\n",
      "\n",
      "The best answer is b. #2021 #Neuroscience #Brain #Vascular #Anatomy #Medical #Science #Education\n",
      "\n",
      "\n",
      "--- Prompt 5 ---\n",
      "📝 Fenthion is ?\n",
      "\n",
      "🤖 Fenthion is? (Choose one)\n",
      "A. Organophosphate insecticide\n",
      "B. C. Organochlorine insecticide\n",
      "C. D. Organosulfur insecticide\n",
      "D. E. Pyrethroid insecticide\n",
      "Answer is: A\n",
      "Explanation: Fenthion is an organophosphate insecticide. Organophosphate insecticides are used in pest control to kill a wide range of insects, but they can be toxic to humans. The organophosphate group works by inhibiting acetylcholinesterase, an enzyme that breaks down acetylcholine, leading to an accumulation of acetylcholine in the nervous system, which can be fatal. Fenthion is used to control a wide range of pests, including insects, rodents, and weeds. It is commonly used in agriculture and public health programs to control mosquitoes and other vectors of disease. Fenthion is also used in household and industrial settings to control pests in buildings and homes. However, due to its potential toxicity\n",
      "\n",
      "\n",
      "--- Prompt 6 ---\n",
      "📝 Feilization usually occurs in which pa of fallopian tube?\n",
      "\n",
      "🤖 Feilization usually occurs in which pa of fallopian tube? A. Isthmus B. Ampulla C. Ampulla + Isthmus D. Isthumus + Infundibulum\n",
      "Answer is: B\n",
      "Step 1: Understand the anatomy of the fallopian tube\n",
      "The fallopian tube is a narrow, muscular tube that connects the ovary to the uterus. It is divided into four parts: the interstitial (or intramural), the isthmus, the ampulla, and the infundibulum.\n",
      "\n",
      "Step 2: Recall the process of fertilization\n",
      "Fertilization is the process by which a sperm meets an egg and combines to form a zygote. This process usually occurs in the ampulla of the fallopian tube, where the egg is released from the ovary and the sperm can meet it.\n",
      "\n",
      "Step 3: Eliminate incorrect options\n",
      "Option A (Isthmus) is incorrect because fertilization does not typically occur in the isthmus, which is the narrower part of\n",
      "\n",
      "\n",
      "--- Prompt 7 ---\n",
      "📝 Behavioral surveillance survey is done in ?\n",
      "\n",
      "🤖 Behavioral surveillance survey is done in? a) School b) Hospital c) Community d) All of the above\n",
      "Answer is: d) All of the above\n",
      "Step 1: Understanding the context of behavioral surveillance survey\n",
      "Behavioral surveillance survey is a method used to collect data on various health-related behaviors and outcomes in a population.\n",
      "\n",
      "Step 2: Identifying the settings where behavioral surveillance survey can be conducted\n",
      "Behavioral surveillance survey can be conducted in various settings, including schools, hospitals, and communities. Each of these settings provides a unique perspective on the behaviors and outcomes of interest.\n",
      "\n",
      "Step 3: Recognizing the importance of comprehensive data collection\n",
      "To get a comprehensive understanding of the health-related behaviors and outcomes, data collection should not be limited to a single setting. Therefore, all the options provided (school, hospital, and community) are relevant for conducting a behavioral surveillance survey.\n",
      "\n",
      "Step 4: Selecting the correct answer\n",
      "Given the information gathered, the correct answer is the one that includes all the options provided (school\n",
      "\n",
      "\n",
      "--- Prompt 8 ---\n",
      "📝 True about alkaptonuria ?\n",
      "\n",
      "🤖 True about alkaptonuria? a) It is a disorder of amino acid metabolism b) It is caused by deficiency of enzyme homogentisate oxidase c) It is characterized by black urine d) All of the above\n",
      "Answer is: d\n",
      "The correct answer is (d) All of the above. Alkaptonuria is a rare genetic disorder that affects the body's ability to break down certain amino acids, specifically tyrosine and phenylalanine. It is caused by a deficiency of the enzyme homogentisate oxidase, which is necessary for the breakdown of these amino acids. As a result, the body accumulates homogentisic acid, a toxic compound that can cause a range of health problems. One of the characteristic symptoms of alkaptonuria is the darkening of urine, which can turn black or dark brown due to the presence of homogentisic acid. Therefore, all of the options a, b, and c are correct.... Read more\n",
      "\n",
      "\n",
      "\n",
      "--- Prompt 9 ---\n",
      "📝 24 hours wearing is possible by which functional appliances:\n",
      "\n",
      "🤖 24 hours wearing is possible by which functional appliances: a) Twin Block b) Activator c) Herbst d) All of the above\n",
      "Answer is: d\n",
      "Explanation: All functional appliances can be worn for 24 hours. The appliances like Twin Block, Activator and Herbst can be worn for 24 hours. They are used to correct the Class II and Class III malocclusions. Functional appliances work by changing the mandibular growth pattern by either protraction of the mandible or retraction of the maxilla. They are used in growing children. The appliances are designed to be worn for 24 hours a day. The patient is asked to remove the appliance for eating and brushing the teeth. The appliances are available in various designs and are used in different age groups. The Twin Block appliance is used in growing children. The appliance works by protracting the mandible and advancing the maxilla. It is used to correct Class II malocclusions. The Activator appliance is used in growing children. The appliance works by\n",
      "\n",
      "\n",
      "--- Prompt 10 ---\n",
      "📝 Afferents for stretch reflexes are carried by which fibers?\n",
      "\n",
      "🤖 Afferents for stretch reflexes are carried by which fibers? Afferents for stretch reflexes are carried by Group II and III afferents.\n",
      "## Step 1: Understanding the question\n",
      "The question asks about the type of afferents that carry signals for stretch reflexes.\n",
      "\n",
      "## Step 2: Identifying the correct afferent group\n",
      "Stretch reflexes are primarily mediated by muscle spindles, which are innervated by afferent nerve fibers. Group II and III afferents are known to be associated with muscle spindles and are responsible for transmitting signals related to muscle stretch and length.\n",
      "\n",
      "## Step 3: Eliminating incorrect options\n",
      "Group I afferents are primarily associated with Golgi tendon organs, which are involved in proprioception and muscle tension, not stretch reflexes. Group IV afferents are involved in nociception, transmitting pain signals.\n",
      "\n",
      "## Step 4: Confirming the correct answer\n",
      "Given the information above, the correct afferents for stretch reflexes are indeed Group II and III a\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Use the first N examples from your validation dataset\n",
    "sample_prompts = dataset[\"test\"][15:25][\"question\"]  # Adjust number as needed\n",
    "\n",
    "# Generation settings\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 200,\n",
    "    \"do_sample\": True,\n",
    "    \"temperature\": 0.7,\n",
    "    \"top_p\": 0.9,\n",
    "    \"top_k\": 50\n",
    "}\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Generate responses\n",
    "for i, prompt in enumerate(sample_prompts, 1):\n",
    "    print(f\"\\n--- Prompt {i} ---\")\n",
    "    print(f\"📝 {prompt}\\n\")\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, **generation_args)\n",
    "\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    print(f\"🤖 {response}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92qz26HKhyXb",
   "metadata": {
    "id": "92qz26HKhyXb"
   },
   "source": [
    "# Converting to GGUF for Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "OrIi446dr_yQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "3ee61673575c40cd9ae4e8d9002877e3",
      "5ecb6b4a73244482b540ef1b2b9b6932",
      "5d3b9c73552b4fdeba24ff6f03558cb9",
      "69ca47179623481cb62dd12b71e7b2f5",
      "45481f2033704e09b7431ea25271c4de",
      "0fbbe3349c154557bcfff77dcf444402",
      "eb4505a98c4a473c9bbf92132f7ca941",
      "c9d124f935874c85a7b75ccf553a1744",
      "3846aed9a8c04da6abf0db31851c8dd8",
      "8e38387250ff4335a5cb13c767e1d53a",
      "7962e84e57b74a94949fff9ab8c9afdb"
     ]
    },
    "id": "OrIi446dr_yQ",
    "outputId": "e31f1598-16d8-41a1-baf7-847b4a6fe9bd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n",
      "model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n",
      "Unsloth: Will remove a cached repo with size 6.0G\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 61.43 out of 83.48 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 45.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Converting llama model. Can use fast conversion = False.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
      "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
      "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
      "\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] might take 10 minutes each.\n",
      " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
      "\n",
      "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
      "Unsloth: CMAKE detected. Finalizing some steps for installation.\n",
      "Unsloth: [1] Converting model at llama3-medmcqa-AmirKhier-gguf into bf16 GGUF format.\n",
      "The output location will be /content/llama.cpp/llama3-medmcqa-AmirKhier-gguf/unsloth.BF16.gguf\n",
      "This might take 3 minutes...\n",
      "INFO:hf-to-gguf:Loading model: llama3-medmcqa-AmirKhier-gguf\n",
      "INFO:hf-to-gguf:Model architecture: LlamaForCausalLM\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:rope_freqs.weight,           torch.float32 --> F32, shape = {64}\n",
      "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:token_embd.weight,           torch.bfloat16 --> BF16, shape = {4096, 128256}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:output.weight,               torch.bfloat16 --> BF16, shape = {4096, 128256}\n",
      "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:output_norm.weight,          torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:gguf: context length = 131072\n",
      "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
      "INFO:hf-to-gguf:gguf: feed forward length = 14336\n",
      "INFO:hf-to-gguf:gguf: head count = 32\n",
      "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
      "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
      "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
      "INFO:hf-to-gguf:gguf: file type = 32\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "INFO:numexpr.utils:NumExpr defaulting to 12 threads.\n",
      "WARNING:gguf.vocab:Unknown separator token '<|begin_of_text|>' in TemplateProcessing<pair>\n",
      "INFO:gguf.vocab:Adding 280147 merge(s).\n",
      "INFO:gguf.vocab:Setting special token type bos to 128000\n",
      "INFO:gguf.vocab:Setting special token type eos to 128009\n",
      "INFO:gguf.vocab:Setting special token type pad to 128004\n",
      "INFO:gguf.vocab:Setting add_bos_token to True\n",
      "INFO:gguf.vocab:Setting add_sep_token to False\n",
      "INFO:gguf.vocab:Setting chat_template to {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- set date_string = \"26 Jul 2024\" %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message + builtin tools #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if builtin_tools is defined or tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{%- if builtin_tools is defined %}\n",
      "    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n",
      "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n",
      "            {%- for arg_name, arg_val in tool_call.arguments | items %}\n",
      "                {{- arg_name + '=\"' + arg_val + '\"' }}\n",
      "                {%- if not loop.last %}\n",
      "                    {{- \", \" }}\n",
      "                {%- endif %}\n",
      "                {%- endfor %}\n",
      "            {{- \")\" }}\n",
      "        {%- else  %}\n",
      "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "            {{- '\"parameters\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- \"}\" }}\n",
      "        {%- endif %}\n",
      "        {%- if builtin_tools is defined %}\n",
      "            {#- This means we're in ipython mode #}\n",
      "            {{- \"<|eom_id|>\" }}\n",
      "        {%- else %}\n",
      "            {{- \"<|eot_id|>\" }}\n",
      "        {%- endif %}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:/content/llama.cpp/llama3-medmcqa-AmirKhier-gguf/unsloth.BF16.gguf: n_tensors = 292, total_size = 16.1G\n",
      "Writing: 100%|██████████| 16.1G/16.1G [01:17<00:00, 207Mbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to /content/llama.cpp/llama3-medmcqa-AmirKhier-gguf/unsloth.BF16.gguf\n",
      "Unsloth: Conversion completed! Output location: /content/llama.cpp/llama3-medmcqa-AmirKhier-gguf/unsloth.BF16.gguf\n",
      "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This might take 20 minutes...\n",
      "main: build = 5780 (caf5681f)\n",
      "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
      "main: quantizing '/content/llama.cpp/llama3-medmcqa-AmirKhier-gguf/unsloth.BF16.gguf' to '/content/llama.cpp/llama3-medmcqa-AmirKhier-gguf/unsloth.Q4_K_M.gguf' as Q4_K_M using 24 threads\n",
      "llama_model_loader: loaded meta data with 29 key-value pairs and 292 tensors from /content/llama.cpp/llama3-medmcqa-AmirKhier-gguf/unsloth.BF16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Llama3 Medmcqa AmirKhier Gguf\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 8.0B\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  14:                          general.file_type u32              = 32\n",
      "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  17:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 128004\n",
      "llama_model_loader: - kv  26:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  27:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - kv  28:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - type  f32:   66 tensors\n",
      "llama_model_loader: - type bf16:  226 tensors\n",
      "[   1/ 292]                        output.weight - [ 4096, 128256,     1,     1], type =   bf16, converting to q6_K .. size =  1002.00 MiB ->   410.98 MiB\n",
      "[   2/ 292]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[   3/ 292]                    rope_freqs.weight - [   64,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[   4/ 292]                    token_embd.weight - [ 4096, 128256,     1,     1], type =   bf16, converting to q4_K .. size =  1002.00 MiB ->   281.81 MiB\n",
      "[   5/ 292]                  blk.0.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[   6/ 292]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[   7/ 292]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[   8/ 292]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[   9/ 292]                  blk.0.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  10/ 292]                blk.0.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  11/ 292]                blk.0.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  12/ 292]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  13/ 292]                  blk.0.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  14/ 292]                  blk.1.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  15/ 292]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  16/ 292]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  17/ 292]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  18/ 292]                  blk.1.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  19/ 292]                blk.1.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  20/ 292]                blk.1.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  21/ 292]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  22/ 292]                  blk.1.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  23/ 292]                  blk.2.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  24/ 292]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  25/ 292]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  26/ 292]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  27/ 292]                  blk.2.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  28/ 292]                blk.2.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  29/ 292]                blk.2.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  30/ 292]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  31/ 292]                  blk.2.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  32/ 292]                  blk.3.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  33/ 292]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  34/ 292]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  35/ 292]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  36/ 292]                  blk.3.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  37/ 292]                blk.3.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  38/ 292]                blk.3.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  39/ 292]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  40/ 292]                  blk.3.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  41/ 292]                  blk.4.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  42/ 292]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  43/ 292]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  44/ 292]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  45/ 292]                  blk.4.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  46/ 292]                blk.4.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  47/ 292]                blk.4.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  48/ 292]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  49/ 292]                  blk.4.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  50/ 292]                  blk.5.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  51/ 292]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  52/ 292]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  53/ 292]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  54/ 292]                  blk.5.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  55/ 292]                blk.5.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  56/ 292]                blk.5.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  57/ 292]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  58/ 292]                  blk.5.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  59/ 292]                  blk.6.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  60/ 292]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  61/ 292]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  62/ 292]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  63/ 292]                  blk.6.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  64/ 292]                blk.6.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  65/ 292]                blk.6.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  66/ 292]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  67/ 292]                  blk.6.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  68/ 292]                  blk.7.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  69/ 292]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  70/ 292]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  71/ 292]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  72/ 292]                  blk.7.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  73/ 292]                blk.7.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  74/ 292]                blk.7.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  75/ 292]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  76/ 292]                  blk.7.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  77/ 292]                  blk.8.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  78/ 292]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  79/ 292]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  80/ 292]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  81/ 292]                  blk.8.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  82/ 292]                blk.8.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  83/ 292]                blk.8.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  84/ 292]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  85/ 292]                  blk.8.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  86/ 292]                  blk.9.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  87/ 292]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  88/ 292]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  89/ 292]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  90/ 292]                  blk.9.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  91/ 292]                blk.9.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  92/ 292]                blk.9.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  93/ 292]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  94/ 292]                  blk.9.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  95/ 292]                 blk.10.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  96/ 292]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  97/ 292]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  98/ 292]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  99/ 292]                 blk.10.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 100/ 292]               blk.10.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 101/ 292]               blk.10.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 102/ 292]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 103/ 292]                 blk.10.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 104/ 292]                 blk.11.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 105/ 292]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 106/ 292]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 107/ 292]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 108/ 292]                 blk.11.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 109/ 292]               blk.11.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 110/ 292]               blk.11.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 111/ 292]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 112/ 292]                 blk.11.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 113/ 292]                 blk.12.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 114/ 292]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 115/ 292]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 116/ 292]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 117/ 292]                 blk.12.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 118/ 292]               blk.12.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 119/ 292]               blk.12.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 120/ 292]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 121/ 292]                 blk.12.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 122/ 292]                 blk.13.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 123/ 292]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 124/ 292]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 125/ 292]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 126/ 292]                 blk.13.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 127/ 292]               blk.13.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 128/ 292]               blk.13.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 129/ 292]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 130/ 292]                 blk.13.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 131/ 292]                 blk.14.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 132/ 292]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 133/ 292]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 134/ 292]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 135/ 292]                 blk.14.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 136/ 292]               blk.14.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 137/ 292]               blk.14.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 138/ 292]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 139/ 292]                 blk.14.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 140/ 292]                 blk.15.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 141/ 292]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 142/ 292]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 143/ 292]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 144/ 292]                 blk.15.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 145/ 292]               blk.15.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 146/ 292]               blk.15.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 147/ 292]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 148/ 292]                 blk.15.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 149/ 292]                 blk.16.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 150/ 292]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 151/ 292]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 152/ 292]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 153/ 292]                 blk.16.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 154/ 292]               blk.16.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 155/ 292]               blk.16.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 156/ 292]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 157/ 292]                 blk.16.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 158/ 292]                 blk.17.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 159/ 292]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 160/ 292]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 161/ 292]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 162/ 292]                 blk.17.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 163/ 292]               blk.17.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 164/ 292]               blk.17.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 165/ 292]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 166/ 292]                 blk.17.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 167/ 292]                 blk.18.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 168/ 292]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 169/ 292]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 170/ 292]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 171/ 292]                 blk.18.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 172/ 292]               blk.18.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 173/ 292]               blk.18.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 174/ 292]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 175/ 292]                 blk.18.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 176/ 292]                 blk.19.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 177/ 292]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 178/ 292]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 179/ 292]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 180/ 292]                 blk.19.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 181/ 292]               blk.19.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 182/ 292]               blk.19.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 183/ 292]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 184/ 292]                 blk.19.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 185/ 292]                 blk.20.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 186/ 292]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 187/ 292]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 188/ 292]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 189/ 292]                 blk.20.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 190/ 292]               blk.20.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 191/ 292]               blk.20.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 192/ 292]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 193/ 292]                 blk.20.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 194/ 292]                 blk.21.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 195/ 292]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 196/ 292]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 197/ 292]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 198/ 292]                 blk.21.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 199/ 292]               blk.21.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 200/ 292]               blk.21.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 201/ 292]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 202/ 292]                 blk.21.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 203/ 292]                 blk.22.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 204/ 292]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 205/ 292]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 206/ 292]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 207/ 292]                 blk.22.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 208/ 292]               blk.22.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 209/ 292]               blk.22.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 210/ 292]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 211/ 292]                 blk.22.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 212/ 292]                 blk.23.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 213/ 292]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 214/ 292]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 215/ 292]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 216/ 292]                 blk.23.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 217/ 292]               blk.23.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 218/ 292]               blk.23.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 219/ 292]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 220/ 292]                 blk.23.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 221/ 292]                 blk.24.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 222/ 292]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 223/ 292]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 224/ 292]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 225/ 292]                 blk.24.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 226/ 292]               blk.24.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 227/ 292]               blk.24.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 228/ 292]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 229/ 292]                 blk.24.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 230/ 292]                 blk.25.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 231/ 292]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 232/ 292]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 233/ 292]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 234/ 292]                 blk.25.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 235/ 292]               blk.25.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 236/ 292]               blk.25.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 237/ 292]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 238/ 292]                 blk.25.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 239/ 292]                 blk.26.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 240/ 292]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 241/ 292]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 242/ 292]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 243/ 292]                 blk.26.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 244/ 292]               blk.26.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 245/ 292]               blk.26.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 246/ 292]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 247/ 292]                 blk.26.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 248/ 292]                 blk.27.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 249/ 292]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 250/ 292]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 251/ 292]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 252/ 292]                 blk.27.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 253/ 292]               blk.27.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 254/ 292]               blk.27.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 255/ 292]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 256/ 292]                 blk.27.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 257/ 292]                 blk.28.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 258/ 292]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 259/ 292]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 260/ 292]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 261/ 292]                 blk.28.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 262/ 292]               blk.28.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 263/ 292]               blk.28.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 264/ 292]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 265/ 292]                 blk.28.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 266/ 292]                 blk.29.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 267/ 292]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 268/ 292]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 269/ 292]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 270/ 292]                 blk.29.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 271/ 292]               blk.29.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 272/ 292]               blk.29.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 273/ 292]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 274/ 292]                 blk.29.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 275/ 292]                 blk.30.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 276/ 292]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 277/ 292]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 278/ 292]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 279/ 292]                 blk.30.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 280/ 292]               blk.30.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 281/ 292]               blk.30.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 282/ 292]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 283/ 292]                 blk.30.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 284/ 292]                 blk.31.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 285/ 292]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 286/ 292]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 287/ 292]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 288/ 292]                 blk.31.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 289/ 292]               blk.31.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 290/ 292]               blk.31.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 291/ 292]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 292/ 292]                 blk.31.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "llama_model_quantize_impl: model size  = 15317.02 MB\n",
      "llama_model_quantize_impl: quant size  =  4685.30 MB\n",
      "\n",
      "main: quantize time = 135660.89 ms\n",
      "main:    total time = 135660.89 ms\n",
      "Unsloth: Conversion completed! Output location: /content/llama.cpp/llama3-medmcqa-AmirKhier-gguf/unsloth.Q4_K_M.gguf\n",
      "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
      "Unsloth: Will use up to 61.11 out of 83.48 RAM for saving.\n",
      "Unsloth: Saving model... This might take 5 minutes ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 65.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Saving tokenizer... Done.\n",
      "Done.\n",
      "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
      "   \\\\   /|    [0] Installing llama.cpp might take 3 minutes.\n",
      "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits might take 3 minutes.\n",
      "\\        /    [2] Converting GGUF 16bits to ['q4_k_m'] might take 10 minutes each.\n",
      " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
      "\n",
      "Unsloth: Installing llama.cpp. This might take 3 minutes...\n",
      "Unsloth: [1] Converting model at Amir32432/llama3-medmcqa-AmirKhier into bf16 GGUF format.\n",
      "The output location will be /content/llama.cpp/Amir32432/llama3-medmcqa-AmirKhier/unsloth.BF16.gguf\n",
      "This might take 3 minutes...\n",
      "INFO:hf-to-gguf:Loading model: llama3-medmcqa-AmirKhier\n",
      "INFO:hf-to-gguf:Model architecture: LlamaForCausalLM\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:rope_freqs.weight,           torch.float32 --> F32, shape = {64}\n",
      "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:token_embd.weight,           torch.bfloat16 --> BF16, shape = {4096, 128256}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.bfloat16 --> BF16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.bfloat16 --> BF16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.bfloat16 --> BF16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00004-of-00004.safetensors'\n",
      "INFO:hf-to-gguf:output.weight,               torch.bfloat16 --> BF16, shape = {4096, 128256}\n",
      "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.bfloat16 --> BF16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:output_norm.weight,          torch.bfloat16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:gguf: context length = 131072\n",
      "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
      "INFO:hf-to-gguf:gguf: feed forward length = 14336\n",
      "INFO:hf-to-gguf:gguf: head count = 32\n",
      "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
      "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
      "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
      "INFO:hf-to-gguf:gguf: file type = 32\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "INFO:numexpr.utils:NumExpr defaulting to 12 threads.\n",
      "WARNING:gguf.vocab:Unknown separator token '<|begin_of_text|>' in TemplateProcessing<pair>\n",
      "INFO:gguf.vocab:Adding 280147 merge(s).\n",
      "INFO:gguf.vocab:Setting special token type bos to 128000\n",
      "INFO:gguf.vocab:Setting special token type eos to 128009\n",
      "INFO:gguf.vocab:Setting special token type pad to 128004\n",
      "INFO:gguf.vocab:Setting add_bos_token to True\n",
      "INFO:gguf.vocab:Setting add_sep_token to False\n",
      "INFO:gguf.vocab:Setting chat_template to {{- bos_token }}\n",
      "{%- if custom_tools is defined %}\n",
      "    {%- set tools = custom_tools %}\n",
      "{%- endif %}\n",
      "{%- if not tools_in_user_message is defined %}\n",
      "    {%- set tools_in_user_message = true %}\n",
      "{%- endif %}\n",
      "{%- if not date_string is defined %}\n",
      "    {%- set date_string = \"26 Jul 2024\" %}\n",
      "{%- endif %}\n",
      "{%- if not tools is defined %}\n",
      "    {%- set tools = none %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
      "{%- if messages[0]['role'] == 'system' %}\n",
      "    {%- set system_message = messages[0]['content']|trim %}\n",
      "    {%- set messages = messages[1:] %}\n",
      "{%- else %}\n",
      "    {%- set system_message = \"\" %}\n",
      "{%- endif %}\n",
      "\n",
      "{#- System message + builtin tools #}\n",
      "{{- \"<|start_header_id|>system<|end_header_id|>\\n\\n\" }}\n",
      "{%- if builtin_tools is defined or tools is not none %}\n",
      "    {{- \"Environment: ipython\\n\" }}\n",
      "{%- endif %}\n",
      "{%- if builtin_tools is defined %}\n",
      "    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\\n\\n\"}}\n",
      "{%- endif %}\n",
      "{{- \"Cutting Knowledge Date: December 2023\\n\" }}\n",
      "{{- \"Today Date: \" + date_string + \"\\n\\n\" }}\n",
      "{%- if tools is not none and not tools_in_user_message %}\n",
      "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "{%- endif %}\n",
      "{{- system_message }}\n",
      "{{- \"<|eot_id|>\" }}\n",
      "\n",
      "{#- Custom tools are passed in a user message with some extra guidance #}\n",
      "{%- if tools_in_user_message and not tools is none %}\n",
      "    {#- Extract the first user message so we can plug it in here #}\n",
      "    {%- if messages | length != 0 %}\n",
      "        {%- set first_user_message = messages[0]['content']|trim %}\n",
      "        {%- set messages = messages[1:] %}\n",
      "    {%- else %}\n",
      "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
      "{%- endif %}\n",
      "    {{- '<|start_header_id|>user<|end_header_id|>\\n\\n' -}}\n",
      "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
      "    {{- \"with its proper arguments that best answers the given prompt.\\n\\n\" }}\n",
      "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
      "    {{- \"Do not use variables.\\n\\n\" }}\n",
      "    {%- for t in tools %}\n",
      "        {{- t | tojson(indent=4) }}\n",
      "        {{- \"\\n\\n\" }}\n",
      "    {%- endfor %}\n",
      "    {{- first_user_message + \"<|eot_id|>\"}}\n",
      "{%- endif %}\n",
      "\n",
      "{%- for message in messages %}\n",
      "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
      "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' }}\n",
      "    {%- elif 'tool_calls' in message %}\n",
      "        {%- if not message.tool_calls|length == 1 %}\n",
      "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
      "        {%- endif %}\n",
      "        {%- set tool_call = message.tool_calls[0].function %}\n",
      "        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n",
      "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n",
      "            {%- for arg_name, arg_val in tool_call.arguments | items %}\n",
      "                {{- arg_name + '=\"' + arg_val + '\"' }}\n",
      "                {%- if not loop.last %}\n",
      "                    {{- \", \" }}\n",
      "                {%- endif %}\n",
      "                {%- endfor %}\n",
      "            {{- \")\" }}\n",
      "        {%- else  %}\n",
      "            {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' -}}\n",
      "            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
      "            {{- '\"parameters\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- \"}\" }}\n",
      "        {%- endif %}\n",
      "        {%- if builtin_tools is defined %}\n",
      "            {#- This means we're in ipython mode #}\n",
      "            {{- \"<|eom_id|>\" }}\n",
      "        {%- else %}\n",
      "            {{- \"<|eot_id|>\" }}\n",
      "        {%- endif %}\n",
      "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
      "        {{- \"<|start_header_id|>ipython<|end_header_id|>\\n\\n\" }}\n",
      "        {%- if message.content is mapping or message.content is iterable %}\n",
      "            {{- message.content | tojson }}\n",
      "        {%- else %}\n",
      "            {{- message.content }}\n",
      "        {%- endif %}\n",
      "        {{- \"<|eot_id|>\" }}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:/content/llama.cpp/Amir32432/llama3-medmcqa-AmirKhier/unsloth.BF16.gguf: n_tensors = 292, total_size = 16.1G\n",
      "Writing: 100%|██████████| 16.1G/16.1G [01:18<00:00, 206Mbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to /content/llama.cpp/Amir32432/llama3-medmcqa-AmirKhier/unsloth.BF16.gguf\n",
      "Unsloth: Conversion completed! Output location: /content/llama.cpp/Amir32432/llama3-medmcqa-AmirKhier/unsloth.BF16.gguf\n",
      "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This might take 20 minutes...\n",
      "main: build = 5780 (caf5681f)\n",
      "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
      "main: quantizing '/content/llama.cpp/Amir32432/llama3-medmcqa-AmirKhier/unsloth.BF16.gguf' to '/content/llama.cpp/Amir32432/llama3-medmcqa-AmirKhier/unsloth.Q4_K_M.gguf' as Q4_K_M using 24 threads\n",
      "llama_model_loader: loaded meta data with 29 key-value pairs and 292 tensors from /content/llama.cpp/Amir32432/llama3-medmcqa-AmirKhier/unsloth.BF16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Llama3 Medmcqa AmirKhier\n",
      "llama_model_loader: - kv   3:                         general.size_label str              = 8.0B\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                       llama.context_length u32              = 131072\n",
      "llama_model_loader: - kv   6:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   7:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   8:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   9:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 500000.000000\n",
      "llama_model_loader: - kv  11:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  12:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  13:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  14:                          general.file_type u32              = 32\n",
      "llama_model_loader: - kv  15:                           llama.vocab_size u32              = 128256\n",
      "llama_model_loader: - kv  16:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  17:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - kv  18:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  19:                         tokenizer.ggml.pre str              = llama-bpe\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  21:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  22:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
      "llama_model_loader: - kv  23:                tokenizer.ggml.bos_token_id u32              = 128000\n",
      "llama_model_loader: - kv  24:                tokenizer.ggml.eos_token_id u32              = 128009\n",
      "llama_model_loader: - kv  25:            tokenizer.ggml.padding_token_id u32              = 128004\n",
      "llama_model_loader: - kv  26:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  27:               tokenizer.ggml.add_sep_token bool             = false\n",
      "llama_model_loader: - kv  28:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
      "llama_model_loader: - type  f32:   66 tensors\n",
      "llama_model_loader: - type bf16:  226 tensors\n",
      "[   1/ 292]                        output.weight - [ 4096, 128256,     1,     1], type =   bf16, converting to q6_K .. size =  1002.00 MiB ->   410.98 MiB\n",
      "[   2/ 292]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[   3/ 292]                    rope_freqs.weight - [   64,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[   4/ 292]                    token_embd.weight - [ 4096, 128256,     1,     1], type =   bf16, converting to q4_K .. size =  1002.00 MiB ->   281.81 MiB\n",
      "[   5/ 292]                  blk.0.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[   6/ 292]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[   7/ 292]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[   8/ 292]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[   9/ 292]                  blk.0.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  10/ 292]                blk.0.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  11/ 292]                blk.0.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  12/ 292]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  13/ 292]                  blk.0.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  14/ 292]                  blk.1.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  15/ 292]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  16/ 292]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  17/ 292]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  18/ 292]                  blk.1.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  19/ 292]                blk.1.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  20/ 292]                blk.1.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  21/ 292]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  22/ 292]                  blk.1.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  23/ 292]                  blk.2.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  24/ 292]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  25/ 292]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  26/ 292]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  27/ 292]                  blk.2.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  28/ 292]                blk.2.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  29/ 292]                blk.2.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  30/ 292]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  31/ 292]                  blk.2.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  32/ 292]                  blk.3.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  33/ 292]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  34/ 292]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  35/ 292]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  36/ 292]                  blk.3.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  37/ 292]                blk.3.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  38/ 292]                blk.3.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  39/ 292]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  40/ 292]                  blk.3.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  41/ 292]                  blk.4.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  42/ 292]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  43/ 292]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  44/ 292]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  45/ 292]                  blk.4.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  46/ 292]                blk.4.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  47/ 292]                blk.4.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  48/ 292]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  49/ 292]                  blk.4.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  50/ 292]                  blk.5.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  51/ 292]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  52/ 292]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  53/ 292]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  54/ 292]                  blk.5.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  55/ 292]                blk.5.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  56/ 292]                blk.5.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  57/ 292]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  58/ 292]                  blk.5.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  59/ 292]                  blk.6.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  60/ 292]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  61/ 292]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  62/ 292]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  63/ 292]                  blk.6.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  64/ 292]                blk.6.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  65/ 292]                blk.6.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  66/ 292]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  67/ 292]                  blk.6.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  68/ 292]                  blk.7.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  69/ 292]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  70/ 292]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  71/ 292]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  72/ 292]                  blk.7.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  73/ 292]                blk.7.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  74/ 292]                blk.7.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  75/ 292]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  76/ 292]                  blk.7.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  77/ 292]                  blk.8.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  78/ 292]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  79/ 292]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  80/ 292]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  81/ 292]                  blk.8.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  82/ 292]                blk.8.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  83/ 292]                blk.8.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  84/ 292]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  85/ 292]                  blk.8.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  86/ 292]                  blk.9.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  87/ 292]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  88/ 292]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  89/ 292]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  90/ 292]                  blk.9.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  91/ 292]                blk.9.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  92/ 292]                blk.9.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  93/ 292]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  94/ 292]                  blk.9.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[  95/ 292]                 blk.10.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[  96/ 292]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  97/ 292]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  98/ 292]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[  99/ 292]                 blk.10.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 100/ 292]               blk.10.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 101/ 292]               blk.10.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 102/ 292]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 103/ 292]                 blk.10.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 104/ 292]                 blk.11.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 105/ 292]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 106/ 292]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 107/ 292]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 108/ 292]                 blk.11.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 109/ 292]               blk.11.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 110/ 292]               blk.11.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 111/ 292]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 112/ 292]                 blk.11.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 113/ 292]                 blk.12.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 114/ 292]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 115/ 292]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 116/ 292]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 117/ 292]                 blk.12.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 118/ 292]               blk.12.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 119/ 292]               blk.12.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 120/ 292]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 121/ 292]                 blk.12.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 122/ 292]                 blk.13.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 123/ 292]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 124/ 292]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 125/ 292]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 126/ 292]                 blk.13.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 127/ 292]               blk.13.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 128/ 292]               blk.13.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 129/ 292]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 130/ 292]                 blk.13.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 131/ 292]                 blk.14.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 132/ 292]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 133/ 292]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 134/ 292]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 135/ 292]                 blk.14.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 136/ 292]               blk.14.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 137/ 292]               blk.14.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 138/ 292]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 139/ 292]                 blk.14.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 140/ 292]                 blk.15.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 141/ 292]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 142/ 292]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 143/ 292]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 144/ 292]                 blk.15.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 145/ 292]               blk.15.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 146/ 292]               blk.15.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 147/ 292]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 148/ 292]                 blk.15.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 149/ 292]                 blk.16.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 150/ 292]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 151/ 292]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 152/ 292]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 153/ 292]                 blk.16.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 154/ 292]               blk.16.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 155/ 292]               blk.16.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 156/ 292]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 157/ 292]                 blk.16.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 158/ 292]                 blk.17.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 159/ 292]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 160/ 292]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 161/ 292]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 162/ 292]                 blk.17.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 163/ 292]               blk.17.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 164/ 292]               blk.17.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 165/ 292]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 166/ 292]                 blk.17.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 167/ 292]                 blk.18.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 168/ 292]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 169/ 292]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 170/ 292]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 171/ 292]                 blk.18.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 172/ 292]               blk.18.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 173/ 292]               blk.18.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 174/ 292]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 175/ 292]                 blk.18.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 176/ 292]                 blk.19.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 177/ 292]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 178/ 292]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 179/ 292]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 180/ 292]                 blk.19.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 181/ 292]               blk.19.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 182/ 292]               blk.19.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 183/ 292]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 184/ 292]                 blk.19.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 185/ 292]                 blk.20.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 186/ 292]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 187/ 292]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 188/ 292]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 189/ 292]                 blk.20.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 190/ 292]               blk.20.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 191/ 292]               blk.20.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 192/ 292]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 193/ 292]                 blk.20.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 194/ 292]                 blk.21.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 195/ 292]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 196/ 292]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 197/ 292]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 198/ 292]                 blk.21.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 199/ 292]               blk.21.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 200/ 292]               blk.21.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 201/ 292]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 202/ 292]                 blk.21.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 203/ 292]                 blk.22.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 204/ 292]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 205/ 292]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 206/ 292]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 207/ 292]                 blk.22.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 208/ 292]               blk.22.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 209/ 292]               blk.22.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 210/ 292]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 211/ 292]                 blk.22.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 212/ 292]                 blk.23.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 213/ 292]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 214/ 292]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 215/ 292]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 216/ 292]                 blk.23.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 217/ 292]               blk.23.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 218/ 292]               blk.23.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 219/ 292]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 220/ 292]                 blk.23.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 221/ 292]                 blk.24.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 222/ 292]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 223/ 292]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 224/ 292]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 225/ 292]                 blk.24.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 226/ 292]               blk.24.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 227/ 292]               blk.24.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 228/ 292]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 229/ 292]                 blk.24.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 230/ 292]                 blk.25.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 231/ 292]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 232/ 292]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 233/ 292]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 234/ 292]                 blk.25.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 235/ 292]               blk.25.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 236/ 292]               blk.25.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 237/ 292]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 238/ 292]                 blk.25.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 239/ 292]                 blk.26.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 240/ 292]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 241/ 292]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 242/ 292]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 243/ 292]                 blk.26.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 244/ 292]               blk.26.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 245/ 292]               blk.26.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 246/ 292]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 247/ 292]                 blk.26.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 248/ 292]                 blk.27.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 249/ 292]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 250/ 292]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 251/ 292]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 252/ 292]                 blk.27.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 253/ 292]               blk.27.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 254/ 292]               blk.27.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 255/ 292]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 256/ 292]                 blk.27.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 257/ 292]                 blk.28.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 258/ 292]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 259/ 292]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 260/ 292]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 261/ 292]                 blk.28.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 262/ 292]               blk.28.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 263/ 292]               blk.28.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 264/ 292]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 265/ 292]                 blk.28.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 266/ 292]                 blk.29.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 267/ 292]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 268/ 292]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 269/ 292]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 270/ 292]                 blk.29.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 271/ 292]               blk.29.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 272/ 292]               blk.29.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 273/ 292]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 274/ 292]                 blk.29.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 275/ 292]                 blk.30.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 276/ 292]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 277/ 292]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 278/ 292]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 279/ 292]                 blk.30.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 280/ 292]               blk.30.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 281/ 292]               blk.30.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 282/ 292]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 283/ 292]                 blk.30.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 284/ 292]                 blk.31.attn_k.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
      "[ 285/ 292]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 286/ 292]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 287/ 292]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =   bf16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
      "[ 288/ 292]                 blk.31.attn_v.weight - [ 4096,  1024,     1,     1], type =   bf16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 289/ 292]               blk.31.ffn_down.weight - [14336,  4096,     1,     1], type =   bf16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 290/ 292]               blk.31.ffn_gate.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "[ 291/ 292]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 292/ 292]                 blk.31.ffn_up.weight - [ 4096, 14336,     1,     1], type =   bf16, converting to q4_K .. size =   112.00 MiB ->    31.50 MiB\n",
      "llama_model_quantize_impl: model size  = 15317.02 MB\n",
      "llama_model_quantize_impl: quant size  =  4685.30 MB\n",
      "\n",
      "main: quantize time = 135824.46 ms\n",
      "main:    total time = 135824.46 ms\n",
      "Unsloth: Conversion completed! Output location: /content/llama.cpp/Amir32432/llama3-medmcqa-AmirKhier/unsloth.Q4_K_M.gguf\n",
      "Unsloth: Uploading GGUF to Huggingface Hub...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee61673575c40cd9ae4e8d9002877e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "unsloth.Q4_K_M.gguf:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GGUF to https://huggingface.co/Amir32432/llama3-medmcqa-AmirKhier\n"
     ]
    }
   ],
   "source": [
    "# Replace this with your HF token (get one from https://huggingface.co/settings/tokens)\n",
    "HF_TOKEN = \"YOUR_TOKEN\"\n",
    "\n",
    "# ✅ Save GGUF locally (quantized to q4_k_m)\n",
    "model.save_pretrained_gguf(\n",
    "    \"YOURGGUF\",  # Output folder for .gguf file(s)\n",
    "    tokenizer,\n",
    "    quantization_method=\"q4_k_m\"\n",
    ")\n",
    "\n",
    "# ✅ Upload GGUF to your Hugging Face repo without overwriting your original model\n",
    "model.push_to_hub_gguf(\n",
    "    \"YOUR_MODEL\",  # Your existing HF repo\n",
    "    tokenizer,\n",
    "    quantization_method=\"q4_k_m\",\n",
    "    token=HF_TOKEN\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vVcLmiYX9yxn",
   "metadata": {
    "id": "vVcLmiYX9yxn"
   },
   "source": [
    "# WebUI Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BABD9Bqc92cE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "BABD9Bqc92cE",
    "outputId": "cbe90ab4-5ab5-42a1-8b6e-174dc6b97888"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting open-webui\n",
      "  Downloading open_webui-0.6.15-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (from open-webui) (1.8.1)\n",
      "Collecting aiocache (from open-webui)\n",
      "  Downloading aiocache-0.12.3-py2.py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: aiofiles in /usr/local/lib/python3.11/dist-packages (from open-webui) (24.1.0)\n",
      "Collecting aiohttp==3.11.11 (from open-webui)\n",
      "  Downloading aiohttp-3.11.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting alembic==1.14.0 (from open-webui)\n",
      "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting anthropic (from open-webui)\n",
      "  Downloading anthropic-0.56.0-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting apscheduler==3.10.4 (from open-webui)\n",
      "  Downloading APScheduler-3.10.4-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting argon2-cffi==23.1.0 (from open-webui)\n",
      "  Downloading argon2_cffi-23.1.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting asgiref==3.8.1 (from open-webui)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting async-timeout (from open-webui)\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting authlib==1.4.1 (from open-webui)\n",
      "  Downloading Authlib-1.4.1-py2.py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting azure-ai-documentintelligence==1.0.2 (from open-webui)\n",
      "  Downloading azure_ai_documentintelligence-1.0.2-py3-none-any.whl.metadata (53 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting azure-identity==1.20.0 (from open-webui)\n",
      "  Downloading azure_identity-1.20.0-py3-none-any.whl.metadata (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.2/81.2 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting azure-storage-blob==12.24.1 (from open-webui)\n",
      "  Downloading azure_storage_blob-12.24.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting bcrypt==4.3.0 (from open-webui)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
      "Collecting black==25.1.0 (from open-webui)\n",
      "  Downloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl.metadata (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting boto3==1.35.53 (from open-webui)\n",
      "  Downloading boto3-1.35.53-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting chromadb==0.6.3 (from open-webui)\n",
      "  Downloading chromadb-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting colbert-ai==0.2.21 (from open-webui)\n",
      "  Downloading colbert_ai-0.2.21-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting docker~=7.1.0 (from open-webui)\n",
      "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting docx2txt==0.8 (from open-webui)\n",
      "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting duckduckgo-search==8.0.2 (from open-webui)\n",
      "  Downloading duckduckgo_search-8.0.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: einops==0.8.1 in /usr/local/lib/python3.11/dist-packages (from open-webui) (0.8.1)\n",
      "Collecting elasticsearch==9.0.1 (from open-webui)\n",
      "  Downloading elasticsearch-9.0.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting extract-msg (from open-webui)\n",
      "  Downloading extract_msg-0.54.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting fake-useragent==2.1.0 (from open-webui)\n",
      "  Downloading fake_useragent-2.1.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting fastapi==0.115.7 (from open-webui)\n",
      "  Downloading fastapi-0.115.7-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting faster-whisper==1.1.1 (from open-webui)\n",
      "  Downloading faster_whisper-1.1.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting firecrawl-py==1.12.0 (from open-webui)\n",
      "  Downloading firecrawl_py-1.12.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting fpdf2==2.8.2 (from open-webui)\n",
      "  Downloading fpdf2-2.8.2-py2.py3-none-any.whl.metadata (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting ftfy==6.2.3 (from open-webui)\n",
      "  Downloading ftfy-6.2.3-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting gcp-storage-emulator>=2024.8.3 (from open-webui)\n",
      "  Downloading gcp_storage_emulator-2024.8.3-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from open-webui) (2.174.0)\n",
      "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.11/dist-packages (from open-webui) (0.2.0)\n",
      "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (from open-webui) (1.2.2)\n",
      "Requirement already satisfied: google-cloud-storage==2.19.0 in /usr/local/lib/python3.11/dist-packages (from open-webui) (2.19.0)\n",
      "Collecting google-genai==1.15.0 (from open-webui)\n",
      "  Downloading google_genai-1.15.0-py3-none-any.whl.metadata (35 kB)\n",
      "Requirement already satisfied: google-generativeai==0.8.5 in /usr/local/lib/python3.11/dist-packages (from open-webui) (0.8.5)\n",
      "Collecting googleapis-common-protos==1.63.2 (from open-webui)\n",
      "  Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-community==0.3.23 (from open-webui)\n",
      "  Downloading langchain_community-0.3.23-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting langchain==0.3.24 (from open-webui)\n",
      "  Downloading langchain-0.3.24-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting langfuse==2.44.0 (from open-webui)\n",
      "  Downloading langfuse-2.44.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting ldap3==2.9.1 (from open-webui)\n",
      "  Downloading ldap3-2.9.1-py2.py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting loguru==0.7.3 (from open-webui)\n",
      "  Downloading loguru-0.7.3-py3-none-any.whl.metadata (22 kB)\n",
      "Collecting markdown==3.7 (from open-webui)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting moto>=5.0.26 (from moto[s3]>=5.0.26->open-webui)\n",
      "  Downloading moto-5.1.6-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: nltk==3.9.1 in /usr/local/lib/python3.11/dist-packages (from open-webui) (3.9.1)\n",
      "Collecting onnxruntime==1.20.1 (from open-webui)\n",
      "  Downloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (from open-webui) (1.93.0)\n",
      "Requirement already satisfied: opencv-python-headless==4.11.0.86 in /usr/local/lib/python3.11/dist-packages (from open-webui) (4.11.0.86)\n",
      "Requirement already satisfied: openpyxl==3.1.5 in /usr/local/lib/python3.11/dist-packages (from open-webui) (3.1.5)\n",
      "Collecting opensearch-py==2.8.0 (from open-webui)\n",
      "  Downloading opensearch_py-2.8.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting pandas==2.2.3 (from open-webui)\n",
      "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting passlib==1.7.4 (from passlib[bcrypt]==1.7.4->open-webui)\n",
      "  Downloading passlib-1.7.4-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting peewee-migrate==1.12.2 (from open-webui)\n",
      "  Downloading peewee_migrate-1.12.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: peewee==3.18.1 in /usr/local/lib/python3.11/dist-packages (from open-webui) (3.18.1)\n",
      "Collecting pgvector==0.4.0 (from open-webui)\n",
      "  Downloading pgvector-0.4.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: pillow==11.2.1 in /usr/local/lib/python3.11/dist-packages (from open-webui) (11.2.1)\n",
      "Collecting pinecone==6.0.2 (from open-webui)\n",
      "  Downloading pinecone-6.0.2-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting playwright==1.49.1 (from open-webui)\n",
      "  Downloading playwright-1.49.1-py3-none-manylinux1_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from open-webui) (5.9.5)\n",
      "Collecting psycopg2-binary==2.9.9 (from open-webui)\n",
      "  Downloading psycopg2_binary-2.9.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\n",
      "Collecting pydantic==2.10.6 (from open-webui)\n",
      "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from open-webui) (0.25.1)\n",
      "Requirement already satisfied: pyjwt==2.10.1 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]==2.10.1->open-webui) (2.10.1)\n",
      "Collecting pymdown-extensions==10.14.2 (from open-webui)\n",
      "  Downloading pymdown_extensions-10.14.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pymilvus==2.5.0 (from open-webui)\n",
      "  Downloading pymilvus-2.5.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting pymongo (from open-webui)\n",
      "  Downloading pymongo-4.13.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Collecting pymysql==1.1.1 (from open-webui)\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting pypandoc==1.15 (from open-webui)\n",
      "  Downloading pypandoc-1.15-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting pypdf==4.3.1 (from open-webui)\n",
      "  Downloading pypdf-4.3.1-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting pytest-docker~=3.1.1 (from open-webui)\n",
      "  Downloading pytest_docker-3.1.2-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: pytest~=8.3.2 in /usr/local/lib/python3.11/dist-packages (from open-webui) (8.3.5)\n",
      "Collecting python-jose==3.4.0 (from open-webui)\n",
      "  Downloading python_jose-3.4.0-py2.py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: python-multipart==0.0.20 in /usr/local/lib/python3.11/dist-packages (from open-webui) (0.0.20)\n",
      "Collecting python-pptx==1.0.2 (from open-webui)\n",
      "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting python-socketio==5.13.0 (from open-webui)\n",
      "  Downloading python_socketio-5.13.0-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pytube==15.0.0 (from open-webui)\n",
      "  Downloading pytube-15.0.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pyxlsb==1.0.10 (from open-webui)\n",
      "  Downloading pyxlsb-1.0.10-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting qdrant-client~=1.12.0 (from open-webui)\n",
      "  Downloading qdrant_client-1.12.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting rank-bm25==0.2.2 (from open-webui)\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting rapidocr-onnxruntime==1.4.4 (from open-webui)\n",
      "  Downloading rapidocr_onnxruntime-1.4.4-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting redis (from open-webui)\n",
      "  Downloading redis-6.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting requests==2.32.4 (from open-webui)\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting restrictedpython==8.0 (from open-webui)\n",
      "  Downloading RestrictedPython-8.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: sentence-transformers==4.1.0 in /usr/local/lib/python3.11/dist-packages (from open-webui) (4.1.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from open-webui) (0.2.0)\n",
      "Requirement already satisfied: soundfile==0.13.1 in /usr/local/lib/python3.11/dist-packages (from open-webui) (0.13.1)\n",
      "Collecting sqlalchemy==2.0.38 (from open-webui)\n",
      "  Downloading SQLAlchemy-2.0.38-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting starlette-compress==1.6.0 (from open-webui)\n",
      "  Downloading starlette_compress-1.6.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting tencentcloud-sdk-python==3.0.1336 (from open-webui)\n",
      "  Downloading tencentcloud_sdk_python-3.0.1336-py2.py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (from open-webui) (0.9.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from open-webui) (4.53.0)\n",
      "Collecting unstructured==0.16.17 (from open-webui)\n",
      "  Downloading unstructured-0.16.17-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting uvicorn==0.34.2 (from uvicorn[standard]==0.34.2->open-webui)\n",
      "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting validators==0.35.0 (from open-webui)\n",
      "  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting xlrd==2.0.1 (from open-webui)\n",
      "  Downloading xlrd-2.0.1-py2.py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting youtube-transcript-api==1.1.0 (from open-webui)\n",
      "  Downloading youtube_transcript_api-1.1.0-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp==3.11.11->open-webui) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp==3.11.11->open-webui) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp==3.11.11->open-webui) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp==3.11.11->open-webui) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp==3.11.11->open-webui) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp==3.11.11->open-webui) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp==3.11.11->open-webui) (1.20.1)\n",
      "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic==1.14.0->open-webui) (1.1.3)\n",
      "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.11/dist-packages (from alembic==1.14.0->open-webui) (4.14.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from apscheduler==3.10.4->open-webui) (1.17.0)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from apscheduler==3.10.4->open-webui) (2025.2)\n",
      "Requirement already satisfied: tzlocal!=3.*,>=2.0 in /usr/local/lib/python3.11/dist-packages (from apscheduler==3.10.4->open-webui) (5.3.1)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.11/dist-packages (from argon2-cffi==23.1.0->open-webui) (21.2.0)\n",
      "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib==1.4.1->open-webui) (43.0.3)\n",
      "Collecting isodate>=0.6.1 (from azure-ai-documentintelligence==1.0.2->open-webui)\n",
      "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting azure-core>=1.30.0 (from azure-ai-documentintelligence==1.0.2->open-webui)\n",
      "  Downloading azure_core-1.34.0-py3-none-any.whl.metadata (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/42.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting msal>=1.30.0 (from azure-identity==1.20.0->open-webui)\n",
      "  Downloading msal-1.32.3-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msal-extensions>=1.2.0 (from azure-identity==1.20.0->open-webui)\n",
      "  Downloading msal_extensions-1.3.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from black==25.1.0->open-webui) (8.2.1)\n",
      "Collecting mypy-extensions>=0.4.3 (from black==25.1.0->open-webui)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.11/dist-packages (from black==25.1.0->open-webui) (24.2)\n",
      "Collecting pathspec>=0.9.0 (from black==25.1.0->open-webui)\n",
      "  Downloading pathspec-0.12.1-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.11/dist-packages (from black==25.1.0->open-webui) (4.3.8)\n",
      "Collecting botocore<1.36.0,>=1.35.53 (from boto3==1.35.53->open-webui)\n",
      "  Downloading botocore-1.35.99-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jmespath<2.0.0,>=0.7.1 (from boto3==1.35.53->open-webui)\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3==1.35.53->open-webui)\n",
      "  Downloading s3transfer-0.10.4-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3->open-webui) (1.2.2.post1)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb==0.6.3->open-webui)\n",
      "  Downloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3->open-webui) (2.0.2)\n",
      "Collecting posthog>=2.4.0 (from chromadb==0.6.3->open-webui)\n",
      "  Downloading posthog-6.0.2-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.6.3->open-webui)\n",
      "  Downloading opentelemetry_api-1.34.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.6.3->open-webui)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.6.3->open-webui)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.55b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==0.6.3->open-webui)\n",
      "  Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3->open-webui) (0.21.2)\n",
      "Collecting pypika>=0.48.9 (from chromadb==0.6.3->open-webui)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3->open-webui) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb==0.6.3->open-webui)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3->open-webui) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3->open-webui) (1.73.1)\n",
      "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3->open-webui) (0.16.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb==0.6.3->open-webui)\n",
      "  Downloading kubernetes-33.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3->open-webui) (8.5.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3->open-webui) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb==0.6.3->open-webui)\n",
      "  Downloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3->open-webui) (3.10.18)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3->open-webui) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb==0.6.3->open-webui) (13.9.4)\n",
      "Collecting bitarray (from colbert-ai==0.2.21->open-webui)\n",
      "  Downloading bitarray-3.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (from colbert-ai==0.2.21->open-webui) (2.14.4)\n",
      "Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (from colbert-ai==0.2.21->open-webui) (3.1.1)\n",
      "Collecting git-python (from colbert-ai==0.2.21->open-webui)\n",
      "  Downloading git_python-1.0.3-py2.py3-none-any.whl.metadata (331 bytes)\n",
      "Collecting python-dotenv (from colbert-ai==0.2.21->open-webui)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting ninja (from colbert-ai==0.2.21->open-webui)\n",
      "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from colbert-ai==0.2.21->open-webui) (1.15.3)\n",
      "Collecting ujson (from colbert-ai==0.2.21->open-webui)\n",
      "  Downloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.3 kB)\n",
      "Collecting primp>=0.15.0 (from duckduckgo-search==8.0.2->open-webui)\n",
      "  Downloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo-search==8.0.2->open-webui) (5.4.0)\n",
      "Collecting elastic-transport<9,>=8.15.1 (from elasticsearch==9.0.1->open-webui)\n",
      "  Downloading elastic_transport-8.17.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from elasticsearch==9.0.1->open-webui) (2.9.0.post0)\n",
      "Collecting starlette<0.46.0,>=0.40.0 (from fastapi==0.115.7->open-webui)\n",
      "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting ctranslate2<5,>=4.0 (from faster-whisper==1.1.1->open-webui)\n",
      "  Downloading ctranslate2-4.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.13 in /usr/local/lib/python3.11/dist-packages (from faster-whisper==1.1.1->open-webui) (0.33.1)\n",
      "Collecting av>=11 (from faster-whisper==1.1.1->open-webui)\n",
      "  Downloading av-14.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from firecrawl-py==1.12.0->open-webui) (15.0.1)\n",
      "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from firecrawl-py==1.12.0->open-webui) (1.6.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.11/dist-packages (from fpdf2==2.8.2->open-webui) (0.7.1)\n",
      "Requirement already satisfied: fonttools>=4.34.0 in /usr/local/lib/python3.11/dist-packages (from fpdf2==2.8.2->open-webui) (4.58.4)\n",
      "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.11/dist-packages (from ftfy==6.2.3->open-webui) (0.2.13)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage==2.19.0->open-webui) (2.38.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage==2.19.0->open-webui) (2.25.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage==2.19.0->open-webui) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage==2.19.0->open-webui) (2.7.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage==2.19.0->open-webui) (1.7.1)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from google-genai==1.15.0->open-webui) (4.9.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.8.5->open-webui) (0.6.15)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai==0.8.5->open-webui) (5.29.5)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.24->open-webui) (0.3.67)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.24->open-webui) (0.3.8)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain==0.3.24->open-webui)\n",
      "  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community==0.3.23->open-webui)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community==0.3.23->open-webui)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community==0.3.23->open-webui)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting backoff>=1.10.0 (from langfuse==2.44.0->open-webui)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: idna<4.0,>=3.7 in /usr/local/lib/python3.11/dist-packages (from langfuse==2.44.0->open-webui) (3.10)\n",
      "Collecting packaging>=22.0 (from black==25.1.0->open-webui)\n",
      "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: wrapt<2.0,>=1.14 in /usr/local/lib/python3.11/dist-packages (from langfuse==2.44.0->open-webui) (1.17.2)\n",
      "Requirement already satisfied: pyasn1>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from ldap3==2.9.1->open-webui) (0.6.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk==3.9.1->open-webui) (1.5.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk==3.9.1->open-webui) (2024.11.6)\n",
      "Collecting coloredlogs (from onnxruntime==1.20.1->open-webui)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.20.1->open-webui) (25.2.10)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime==1.20.1->open-webui) (1.13.1)\n",
      "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl==3.1.5->open-webui) (2.0.0)\n",
      "Requirement already satisfied: urllib3!=2.2.0,!=2.2.1,<3,>=1.26.19 in /usr/local/lib/python3.11/dist-packages (from opensearch-py==2.8.0->open-webui) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2024.07.04 in /usr/local/lib/python3.11/dist-packages (from opensearch-py==2.8.0->open-webui) (2025.6.15)\n",
      "Collecting Events (from opensearch-py==2.8.0->open-webui)\n",
      "  Downloading Events-0.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas==2.2.3->open-webui) (2025.2)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone==6.0.2->open-webui)\n",
      "  Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting greenlet==3.1.1 (from playwright==1.49.1->open-webui)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting pyee==12.0.0 (from playwright==1.49.1->open-webui)\n",
      "  Downloading pyee-12.0.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic==2.10.6->open-webui) (0.7.0)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic==2.10.6->open-webui)\n",
      "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: setuptools>69 in /usr/local/lib/python3.11/dist-packages (from pymilvus==2.5.0->open-webui) (75.2.0)\n",
      "Collecting grpcio>=1.58.0 (from chromadb==0.6.3->open-webui)\n",
      "  Downloading grpcio-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
      "Collecting milvus-lite>=2.4.0 (from pymilvus==2.5.0->open-webui)\n",
      "  Downloading milvus_lite-2.5.1-py3-none-manylinux2014_x86_64.whl.metadata (10.0 kB)\n",
      "Collecting ecdsa!=0.15 (from python-jose==3.4.0->open-webui)\n",
      "  Downloading ecdsa-0.19.1-py2.py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: rsa!=4.1.1,!=4.4,<5.0,>=4.0 in /usr/local/lib/python3.11/dist-packages (from python-jose==3.4.0->open-webui) (4.9.1)\n",
      "Collecting pyasn1>=0.4.6 (from ldap3==2.9.1->open-webui)\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting XlsxWriter>=0.5.7 (from python-pptx==1.0.2->open-webui)\n",
      "  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting bidict>=0.21.0 (from python-socketio==5.13.0->open-webui)\n",
      "  Downloading bidict-0.23.1-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting python-engineio>=4.11.0 (from python-socketio==5.13.0->open-webui)\n",
      "  Downloading python_engineio-4.12.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pyclipper>=1.2.0 (from rapidocr-onnxruntime==1.4.4->open-webui)\n",
      "  Downloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: opencv-python>=4.5.1.48 in /usr/local/lib/python3.11/dist-packages (from rapidocr-onnxruntime==1.4.4->open-webui) (4.11.0.86)\n",
      "Requirement already satisfied: Shapely!=2.0.4,>=1.7.1 in /usr/local/lib/python3.11/dist-packages (from rapidocr-onnxruntime==1.4.4->open-webui) (2.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests==2.32.4->open-webui) (3.4.2)\n",
      "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==4.1.0->open-webui) (2.6.0+cu124)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers==4.1.0->open-webui) (1.6.1)\n",
      "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.11/dist-packages (from soundfile==0.13.1->open-webui) (1.17.1)\n",
      "Collecting brotli>=1 (from starlette-compress==1.6.0->open-webui)\n",
      "  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: zstandard>=0.15 in /usr/local/lib/python3.11/dist-packages (from starlette-compress==1.6.0->open-webui) (0.23.0)\n",
      "Requirement already satisfied: chardet in /usr/local/lib/python3.11/dist-packages (from unstructured==0.16.17->open-webui) (5.2.0)\n",
      "Collecting filetype (from unstructured==0.16.17->open-webui)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured==0.16.17->open-webui)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from unstructured==0.16.17->open-webui) (4.13.4)\n",
      "Collecting emoji (from unstructured==0.16.17->open-webui)\n",
      "  Downloading emoji-2.14.1-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting python-iso639 (from unstructured==0.16.17->open-webui)\n",
      "  Downloading python_iso639-2025.2.18-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting langdetect (from unstructured==0.16.17->open-webui)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Collecting numpy>=1.22.5 (from chromadb==0.6.3->open-webui)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rapidfuzz (from unstructured==0.16.17->open-webui)\n",
      "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting unstructured-client (from unstructured==0.16.17->open-webui)\n",
      "  Downloading unstructured_client-0.37.4-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting python-oxmsg (from unstructured==0.16.17->open-webui)\n",
      "  Downloading python_oxmsg-0.0.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: html5lib in /usr/local/lib/python3.11/dist-packages (from unstructured==0.16.17->open-webui) (1.1)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn==0.34.2->uvicorn[standard]==0.34.2->open-webui) (0.16.0)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]==0.34.2->open-webui)\n",
      "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]==0.34.2->open-webui)\n",
      "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]==0.34.2->open-webui)\n",
      "  Downloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai==0.8.5->open-webui) (1.26.1)\n",
      "Collecting fs (from gcp-storage-emulator>=2024.8.3->open-webui)\n",
      "  Downloading fs-2.4.16-py2.py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting xmltodict (from moto>=5.0.26->moto[s3]>=5.0.26->open-webui)\n",
      "  Downloading xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: werkzeug!=2.2.0,!=2.2.1,>=0.5 in /usr/local/lib/python3.11/dist-packages (from moto>=5.0.26->moto[s3]>=5.0.26->open-webui) (3.1.3)\n",
      "Collecting responses!=0.25.5,>=0.15.0 (from moto>=5.0.26->moto[s3]>=5.0.26->open-webui)\n",
      "  Downloading responses-0.25.7-py3-none-any.whl.metadata (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: Jinja2>=2.10.1 in /usr/local/lib/python3.11/dist-packages (from moto>=5.0.26->moto[s3]>=5.0.26->open-webui) (3.1.6)\n",
      "Collecting py-partiql-parser==0.6.1 (from moto[s3]>=5.0.26->open-webui)\n",
      "  Downloading py_partiql_parser-0.6.1-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: iniconfig in /usr/local/lib/python3.11/dist-packages (from pytest~=8.3.2->open-webui) (2.1.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.11/dist-packages (from pytest~=8.3.2->open-webui) (1.6.0)\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client~=1.12.0->open-webui)\n",
      "  Downloading grpcio_tools-1.73.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting portalocker<3.0.0,>=2.7.0 (from qdrant-client~=1.12.0->open-webui)\n",
      "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers->open-webui) (3.18.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->open-webui) (0.5.3)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic->open-webui) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic->open-webui) (0.10.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic->open-webui) (1.3.1)\n",
      "Collecting olefile==0.47 (from extract-msg->open-webui)\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting compressed-rtf<2,>=1.0.6 (from extract-msg->open-webui)\n",
      "  Downloading compressed_rtf-1.0.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting ebcdic<2,>=1.1.1 (from extract-msg->open-webui)\n",
      "  Downloading ebcdic-1.1.1-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting RTFDE<0.2,>=0.1.1 (from extract-msg->open-webui)\n",
      "  Downloading rtfde-0.1.2.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting red-black-tree-mod<=1.23,>=1.20 (from extract-msg->open-webui)\n",
      "  Downloading red-black-tree-mod-1.22.tar.gz (34 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->open-webui) (0.22.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->open-webui) (4.2.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib->open-webui) (2.0.0)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo->open-webui)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->unstructured==0.16.17->open-webui) (2.7)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb==0.6.3->open-webui) (1.2.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.0->soundfile==0.13.1->open-webui) (2.22)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.23->open-webui)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.23->open-webui)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage==2.19.0->open-webui) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage==2.19.0->open-webui) (0.4.2)\n",
      "INFO: pip is looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-tools>=1.41.0 (from qdrant-client~=1.12.0->open-webui)\n",
      "  Downloading grpcio_tools-1.73.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.72.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.72.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.71.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.70.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.69.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-tools to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_tools-1.68.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.68.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "  Downloading grpcio_tools-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->open-webui) (3.2.3)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb==0.6.3->open-webui) (1.0.9)\n",
      "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.11/dist-packages (from httpx[http2]>=0.20.0->qdrant-client~=1.12.0->open-webui) (4.2.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper==1.1.1->open-webui) (2025.3.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.13->faster-whisper==1.1.1->open-webui) (1.1.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=2.10.1->moto>=5.0.26->moto[s3]>=5.0.26->open-webui) (3.0.2)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.6.3->open-webui) (1.8.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb==0.6.3->open-webui) (3.3.1)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb==0.6.3->open-webui)\n",
      "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain==0.3.24->open-webui) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain==0.3.24->open-webui) (1.0.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb==0.6.3->open-webui) (8.7.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->open-webui)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.34.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.6.3->open-webui)\n",
      "  Downloading opentelemetry_proto-1.34.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->open-webui)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.55b1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting opentelemetry-instrumentation==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->open-webui)\n",
      "  Downloading opentelemetry_instrumentation-0.55b1-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->open-webui)\n",
      "  Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.55b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.6.3->open-webui)\n",
      "  Downloading opentelemetry_util_http-0.55b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.23->open-webui) (0.4.1)\n",
      "Collecting simple-websocket>=0.10.0 (from python-engineio>=4.11.0->python-socketio==5.13.0->open-webui)\n",
      "  Downloading simple_websocket-1.1.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb==0.6.3->open-webui) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb==0.6.3->open-webui) (2.19.2)\n",
      "Collecting lark~=1.1.8 (from RTFDE<0.2,>=0.1.1->extract-msg->open-webui)\n",
      "  Downloading lark-1.1.9-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting oletools>=0.56 (from RTFDE<0.2,>=0.1.1->extract-msg->open-webui)\n",
      "  Downloading oletools-0.60.2-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==4.1.0->open-webui) (3.5)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers==4.1.0->open-webui)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers==4.1.0->open-webui)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers==4.1.0->open-webui)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers==4.1.0->open-webui)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers==4.1.0->open-webui)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers==4.1.0->open-webui)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers==4.1.0->open-webui)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers==4.1.0->open-webui)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers==4.1.0->open-webui)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==4.1.0->open-webui) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==4.1.0->open-webui) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==4.1.0->open-webui) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers==4.1.0->open-webui)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers==4.1.0->open-webui) (3.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime==1.20.1->open-webui) (1.3.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb==0.6.3->open-webui) (1.5.4)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.20.1->open-webui)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->colbert-ai==0.2.21->open-webui) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets->colbert-ai==0.2.21->open-webui) (0.3.7)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets->colbert-ai==0.2.21->open-webui) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets->colbert-ai==0.2.21->open-webui) (0.70.15)\n",
      "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from flask->colbert-ai==0.2.21->open-webui) (1.9.0)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from flask->colbert-ai==0.2.21->open-webui) (2.2.0)\n",
      "Collecting appdirs~=1.4.3 (from fs->gcp-storage-emulator>=2024.8.3->open-webui)\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Requirement already satisfied: gitpython in /usr/local/lib/python3.11/dist-packages (from git-python->colbert-ai==0.2.21->open-webui) (3.1.44)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.11/dist-packages (from html5lib->unstructured==0.16.17->open-webui) (0.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers==4.1.0->open-webui) (3.6.0)\n",
      "INFO: pip is looking at multiple versions of unstructured-client to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting unstructured-client (from unstructured==0.16.17->open-webui)\n",
      "  Downloading unstructured_client-0.37.2-py3-none-any.whl.metadata (20 kB)\n",
      "  Downloading unstructured_client-0.37.1-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading unstructured_client-0.36.0-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading unstructured_client-0.35.0-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading unstructured_client-0.34.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting eval-type-backport>=0.2.0 (from unstructured-client->unstructured==0.16.17->open-webui)\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting unstructured-client (from unstructured==0.16.17->open-webui)\n",
      "  Downloading unstructured_client-0.33.1-py3-none-any.whl.metadata (21 kB)\n",
      "  Downloading unstructured_client-0.33.0-py3-none-any.whl.metadata (23 kB)\n",
      "INFO: pip is still looking at multiple versions of unstructured-client to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading unstructured_client-0.32.4-py3-none-any.whl.metadata (23 kB)\n",
      "  Downloading unstructured_client-0.32.3-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai==0.8.5->open-webui) (1.71.2)\n",
      "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client~=1.12.0->open-webui) (6.1.0)\n",
      "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client~=1.12.0->open-webui) (4.1.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.6.3->open-webui) (3.23.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain==0.3.24->open-webui) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==0.6.3->open-webui) (0.1.2)\n",
      "Collecting easygui (from oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg->open-webui)\n",
      "  Downloading easygui-0.98.3-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting colorclass (from oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg->open-webui)\n",
      "  Downloading colorclass-2.2.2-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pcodedmp>=1.2.5 (from oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg->open-webui)\n",
      "  Downloading pcodedmp-1.2.6-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting msoffcrypto-tool (from oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg->open-webui)\n",
      "  Downloading msoffcrypto_tool-5.4.2-py3-none-any.whl.metadata (10 kB)\n",
      "INFO: pip is looking at multiple versions of pyasn1-modules to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3.0dev,>=2.26.1->google-cloud-storage==2.19.0->open-webui)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting wsproto (from simple-websocket>=0.10.0->python-engineio>=4.11.0->python-socketio==5.13.0->open-webui)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython->git-python->colbert-ai==0.2.21->open-webui) (4.0.12)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython->git-python->colbert-ai==0.2.21->open-webui) (5.0.2)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai==0.8.5->open-webui)\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading open_webui-0.6.15-py3-none-any.whl (133.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.11.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading APScheduler-3.10.4-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.3/59.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading argon2_cffi-23.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading Authlib-1.4.1-py2.py3-none-any.whl (225 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.6/225.6 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_ai_documentintelligence-1.0.2-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.0/106.0 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_identity-1.20.0-py3-none-any.whl (188 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.2/188.2 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_storage_blob-12.24.1-py3-none-any.whl (408 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.4/408.4 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_34_x86_64.whl (284 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading black-25.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading boto3-1.35.53-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chromadb-0.6.3-py3-none-any.whl (611 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading colbert_ai-0.2.21-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.1/116.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading duckduckgo_search-8.0.2-py3-none-any.whl (18 kB)\n",
      "Downloading elasticsearch-9.0.1-py3-none-any.whl (905 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m905.5/905.5 kB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fake_useragent-2.1.0-py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.8/125.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastapi-0.115.7-py3-none-any.whl (94 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading faster_whisper-1.1.1-py3-none-any.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading firecrawl_py-1.12.0-py3-none-any.whl (31 kB)\n",
      "Downloading fpdf2-2.8.2-py2.py3-none-any.whl (236 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.3/236.3 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ftfy-6.2.3-py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.0/43.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading google_genai-1.15.0-py3-none-any.whl (171 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.3/171.3 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl (220 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain-0.3.24-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.3.23-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langfuse-2.44.0-py3-none-any.whl (195 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.9/195.9 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ldap3-2.9.1-py2.py3-none-any.whl (432 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m432.2/432.2 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading loguru-0.7.3-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.3/106.3 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.20.1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m120.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opensearch_py-2.8.0-py3-none-any.whl (353 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.5/353.5 kB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m128.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading passlib-1.7.4-py2.py3-none-any.whl (525 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.6/525.6 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peewee_migrate-1.12.2-py3-none-any.whl (18 kB)\n",
      "Downloading pgvector-0.4.0-py3-none-any.whl (27 kB)\n",
      "Downloading pinecone-6.0.2-py3-none-any.whl (421 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.9/421.9 kB\u001b[0m \u001b[31m40.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading playwright-1.49.1-py3-none-manylinux1_x86_64.whl (44.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/44.2 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading psycopg2_binary-2.9.9-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m106.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pymdown_extensions-10.14.2-py3-none-any.whl (264 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.5/264.5 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pymilvus-2.5.0-py3-none-any.whl (212 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.8/212.8 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pypandoc-1.15-py3-none-any.whl (21 kB)\n",
      "Downloading pypdf-4.3.1-py3-none-any.whl (295 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_jose-3.4.0-py2.py3-none-any.whl (34 kB)\n",
      "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_socketio-5.13.0-py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyxlsb-1.0.10-py2.py3-none-any.whl (23 kB)\n",
      "Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Downloading rapidocr_onnxruntime-1.4.4-py3-none-any.whl (14.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.8/64.8 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading RestrictedPython-8.0-py3-none-any.whl (27 kB)\n",
      "Downloading SQLAlchemy-2.0.38-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m115.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette_compress-1.6.0-py3-none-any.whl (11 kB)\n",
      "Downloading tencentcloud_sdk_python-3.0.1336-py2.py3-none-any.whl (12.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m136.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unstructured-0.16.17-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading validators-0.35.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xlrd-2.0.1-py2.py3-none-any.whl (96 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.5/96.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading youtube_transcript_api-1.1.0-py3-none-any.whl (485 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m485.7/485.7 kB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.1.1-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (602 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m602.4/602.4 kB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyee-12.0.0-py3-none-any.whl (14 kB)\n",
      "Downloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading gcp_storage_emulator-2024.8.3-py3-none-any.whl (19 kB)\n",
      "Downloading moto-5.1.6-py3-none-any.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m135.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading py_partiql_parser-0.6.1-py2.py3-none-any.whl (23 kB)\n",
      "Downloading pytest_docker-3.1.2-py3-none-any.whl (8.5 kB)\n",
      "Downloading qdrant_client-1.12.2-py3-none-any.whl (267 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.2/267.2 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiocache-0.12.3-py2.py3-none-any.whl (28 kB)\n",
      "Downloading anthropic-0.56.0-py3-none-any.whl (289 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.6/289.6 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Downloading extract_msg-0.54.1-py3-none-any.whl (335 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.0/336.0 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pymongo-4.13.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading redis-6.2.0-py3-none-any.whl (278 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.7/278.7 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading av-14.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.3/35.3 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading azure_core-1.34.0-py3-none-any.whl (207 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.4/207.4 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading bidict-0.23.1-py3-none-any.whl (32 kB)\n",
      "Downloading botocore-1.35.99-py3-none-any.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m129.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m121.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading compressed_rtf-1.0.7-py3-none-any.whl (8.0 kB)\n",
      "Downloading ctranslate2-4.6.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ebcdic-1.1.1-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.5/128.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ecdsa-0.19.1-py2.py3-none-any.whl (150 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.6/150.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading elastic_transport-8.17.1-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m124.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_tools-1.67.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
      "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Downloading kubernetes-33.1.0-py2.py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.0/363.0 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading milvus_lite-2.5.1-py3-none-manylinux2014_x86_64.whl (55.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.3/55.3 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.1.0-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msal-1.32.3-py3-none-any.whl (115 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.4/115.4 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msal_extensions-1.3.1-py3-none-any.whl (20 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.34.1-py3-none-any.whl (65 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.34.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.34.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.34.1-py3-none-any.whl (55 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.55b1-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.55b1-py3-none-any.whl (31 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.55b1-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.55b1-py3-none-any.whl (196 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_util_http-0.55b1-py3-none-any.whl (7.3 kB)\n",
      "Downloading opentelemetry_sdk-1.34.1-py3-none-any.whl (118 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pathspec-0.12.1-py3-none-any.whl (31 kB)\n",
      "Downloading pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Downloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
      "Downloading posthog-6.0.2-py3-none-any.whl (104 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading primp-0.15.0-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m115.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (969 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m68.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading python_engineio-4.12.2-py3-none-any.whl (59 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading responses-0.25.7-py3-none-any.whl (34 kB)\n",
      "Downloading rtfde-0.1.2.1-py3-none-any.whl (36 kB)\n",
      "Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m131.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m111.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ujson-5.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m121.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (453 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m453.1/453.1 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitarray-3.4.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.0/316.0 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading emoji-2.14.1-py3-none-any.whl (590 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading Events-0.5-py3-none-any.whl (6.8 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading fs-2.4.16-py2.py3-none-any.whl (135 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.3/135.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading git_python-1.0.3-py2.py3-none-any.whl (1.9 kB)\n",
      "Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_iso639-2025.2.18-py3-none-any.whl (167 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.2-py3-none-any.whl (31 kB)\n",
      "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m104.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unstructured_client-0.32.3-py3-none-any.whl (180 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.6/180.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading lark-1.1.9-py3-none-any.whl (111 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading oletools-0.60.2-py2.py3-none-any.whl (989 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m989.4/989.4 kB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading simple_websocket-1.1.0-py3-none-any.whl (13 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading grpcio_status-1.67.1-py3-none-any.whl (14 kB)\n",
      "Downloading pcodedmp-1.2.6-py2.py3-none-any.whl (30 kB)\n",
      "Downloading colorclass-2.2.2-py2.py3-none-any.whl (18 kB)\n",
      "Downloading easygui-0.98.3-py2.py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msoffcrypto_tool-5.4.2-py3-none-any.whl (48 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.7/48.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: docx2txt, pypika, red-black-tree-mod, langdetect\n",
      "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=05240f024c55bf8bd1b9593832db8acde65dc3bdbd0f1663531ec33f1a7360f9\n",
      "  Stored in directory: /root/.cache/pip/wheels/0f/0e/7a/3094a4ceefe657bff7e12dd9592a9d5b6487ef4338ace0afa6\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=88aa7d5ef41bc991879c03127e77e3550c3dc41307a71f8b96ee6ef301f7443b\n",
      "  Stored in directory: /root/.cache/pip/wheels/a3/01/bd/4c40ceb9d5354160cb186dcc153360f4ab7eb23e2b24daf96d\n",
      "  Building wheel for red-black-tree-mod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for red-black-tree-mod: filename=red_black_tree_mod-1.22-py3-none-any.whl size=19237 sha256=639b6b7dc3ef4ea28adf9c241d4a305f60827f2bf440f86dc47fb83addd239c6\n",
      "  Stored in directory: /root/.cache/pip/wheels/6a/ae/7f/2933e7ea294e0f7e79b1b8cc304f89ad10886c8bb943b41003\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993223 sha256=b7f6723d796fdaa04b9a5184da9e48da49ff21eea3c6ea878d575e0c98cd1b31\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/f2/b2/e5ca405801e05eb7c8ed5b3b4bcf1fcabcd6272c167640072e\n",
      "Successfully built docx2txt pypika red-black-tree-mod langdetect\n",
      "Installing collected packages: red-black-tree-mod, pyxlsb, pypika, pyclipper, pyasn1, py-partiql-parser, passlib, filetype, Events, ebcdic, easygui, durationpy, docx2txt, compressed-rtf, brotli, bitarray, appdirs, aiocache, xmltodict, XlsxWriter, xlrd, wsproto, validators, uvloop, uvicorn, ujson, restrictedpython, requests, redis, rapidfuzz, pytube, python-magic, python-iso639, python-dotenv, pypdf, pypandoc, pymysql, pyee, pydantic-core, pyasn1-modules, psycopg2-binary, primp, portalocker, pinecone-plugin-interface, peewee-migrate, pathspec, packaging, overrides, opentelemetry-util-http, opentelemetry-proto, olefile, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, ninja, mypy-extensions, mmh3, milvus-lite, markdown, loguru, ldap3, lark, langdetect, jmespath, isodate, humanfriendly, httpx-sse, httptools, grpcio, greenlet, googleapis-common-protos, ftfy, fs, fpdf2, fake-useragent, eval-type-backport, emoji, elastic-transport, ecdsa, dnspython, colorclass, bidict, bcrypt, backoff, av, async-timeout, asgiref, apscheduler, youtube-transcript-api, watchfiles, typing-inspect, tencentcloud-sdk-python, starlette, sqlalchemy, simple-websocket, responses, rank-bm25, python-pptx, python-oxmsg, python-jose, pymongo, pymdown-extensions, pydantic, posthog, playwright, pinecone, pgvector, pandas, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, opensearch-py, nvidia-cusparse-cu12, nvidia-cudnn-cu12, marshmallow, grpcio-tools, grpcio-status, gcp-storage-emulator, elasticsearch, duckduckgo-search, docker, ctranslate2, coloredlogs, chroma-hnswlib, botocore, black, azure-core, aiohttp, unstructured-client, starlette-compress, s3transfer, python-engineio, pytest-docker, pymilvus, pydantic-settings, opentelemetry-semantic-conventions, onnxruntime, nvidia-cusolver-cu12, msoffcrypto-tool, langsmith, langfuse, kubernetes, google-genai, git-python, firecrawl-py, fastapi, dataclasses-json, azure-storage-blob, azure-ai-documentintelligence, authlib, argon2-cffi, anthropic, alembic, unstructured, rapidocr-onnxruntime, qdrant-client, python-socketio, opentelemetry-sdk, opentelemetry-instrumentation, msal, faster-whisper, boto3, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, msal-extensions, moto, colbert-ai, opentelemetry-instrumentation-fastapi, langchain, azure-identity, langchain-community, chromadb, pcodedmp, oletools, RTFDE, extract-msg, open-webui\n",
      "  Attempting uninstall: pyasn1\n",
      "    Found existing installation: pyasn1 0.6.1\n",
      "    Uninstalling pyasn1-0.6.1:\n",
      "      Successfully uninstalled pyasn1-0.6.1\n",
      "  Attempting uninstall: xlrd\n",
      "    Found existing installation: xlrd 2.0.2\n",
      "    Uninstalling xlrd-2.0.2:\n",
      "      Successfully uninstalled xlrd-2.0.2\n",
      "  Attempting uninstall: uvicorn\n",
      "    Found existing installation: uvicorn 0.35.0\n",
      "    Uninstalling uvicorn-0.35.0:\n",
      "      Successfully uninstalled uvicorn-0.35.0\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.3\n",
      "    Uninstalling requests-2.32.3:\n",
      "      Successfully uninstalled requests-2.32.3\n",
      "  Attempting uninstall: pydantic-core\n",
      "    Found existing installation: pydantic_core 2.33.2\n",
      "    Uninstalling pydantic_core-2.33.2:\n",
      "      Successfully uninstalled pydantic_core-2.33.2\n",
      "  Attempting uninstall: pyasn1-modules\n",
      "    Found existing installation: pyasn1_modules 0.4.2\n",
      "    Uninstalling pyasn1_modules-0.4.2:\n",
      "      Successfully uninstalled pyasn1_modules-0.4.2\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 24.2\n",
      "    Uninstalling packaging-24.2:\n",
      "      Successfully uninstalled packaging-24.2\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "  Attempting uninstall: markdown\n",
      "    Found existing installation: Markdown 3.8.2\n",
      "    Uninstalling Markdown-3.8.2:\n",
      "      Successfully uninstalled Markdown-3.8.2\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.73.1\n",
      "    Uninstalling grpcio-1.73.1:\n",
      "      Successfully uninstalled grpcio-1.73.1\n",
      "  Attempting uninstall: greenlet\n",
      "    Found existing installation: greenlet 3.2.3\n",
      "    Uninstalling greenlet-3.2.3:\n",
      "      Successfully uninstalled greenlet-3.2.3\n",
      "  Attempting uninstall: googleapis-common-protos\n",
      "    Found existing installation: googleapis-common-protos 1.70.0\n",
      "    Uninstalling googleapis-common-protos-1.70.0:\n",
      "      Successfully uninstalled googleapis-common-protos-1.70.0\n",
      "  Attempting uninstall: starlette\n",
      "    Found existing installation: starlette 0.46.2\n",
      "    Uninstalling starlette-0.46.2:\n",
      "      Successfully uninstalled starlette-0.46.2\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.41\n",
      "    Uninstalling SQLAlchemy-2.0.41:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.41\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 2.11.7\n",
      "    Uninstalling pydantic-2.11.7:\n",
      "      Successfully uninstalled pydantic-2.11.7\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.2\n",
      "    Uninstalling pandas-2.2.2:\n",
      "      Successfully uninstalled pandas-2.2.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: grpcio-status\n",
      "    Found existing installation: grpcio-status 1.71.2\n",
      "    Uninstalling grpcio-status-1.71.2:\n",
      "      Successfully uninstalled grpcio-status-1.71.2\n",
      "  Attempting uninstall: aiohttp\n",
      "    Found existing installation: aiohttp 3.11.15\n",
      "    Uninstalling aiohttp-3.11.15:\n",
      "      Successfully uninstalled aiohttp-3.11.15\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.4.4\n",
      "    Uninstalling langsmith-0.4.4:\n",
      "      Successfully uninstalled langsmith-0.4.4\n",
      "  Attempting uninstall: google-genai\n",
      "    Found existing installation: google-genai 1.23.0\n",
      "    Uninstalling google-genai-1.23.0:\n",
      "      Successfully uninstalled google-genai-1.23.0\n",
      "  Attempting uninstall: fastapi\n",
      "    Found existing installation: fastapi 0.115.14\n",
      "    Uninstalling fastapi-0.115.14:\n",
      "      Successfully uninstalled fastapi-0.115.14\n",
      "  Attempting uninstall: argon2-cffi\n",
      "    Found existing installation: argon2-cffi 25.1.0\n",
      "    Uninstalling argon2-cffi-25.1.0:\n",
      "      Successfully uninstalled argon2-cffi-25.1.0\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.26\n",
      "    Uninstalling langchain-0.3.26:\n",
      "      Successfully uninstalled langchain-0.3.26\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
      "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.4 which is incompatible.\n",
      "google-cloud-bigquery 3.34.0 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\n",
      "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
      "db-dtypes 1.4.3 requires packaging>=24.2.0, but you have packaging 23.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Events-0.5 RTFDE-0.1.2.1 XlsxWriter-3.2.5 aiocache-0.12.3 aiohttp-3.11.11 alembic-1.14.0 anthropic-0.56.0 appdirs-1.4.4 apscheduler-3.10.4 argon2-cffi-23.1.0 asgiref-3.8.1 async-timeout-5.0.1 authlib-1.4.1 av-14.4.0 azure-ai-documentintelligence-1.0.2 azure-core-1.34.0 azure-identity-1.20.0 azure-storage-blob-12.24.1 backoff-2.2.1 bcrypt-4.3.0 bidict-0.23.1 bitarray-3.4.3 black-25.1.0 boto3-1.35.53 botocore-1.35.99 brotli-1.1.0 chroma-hnswlib-0.7.6 chromadb-0.6.3 colbert-ai-0.2.21 colorclass-2.2.2 coloredlogs-15.0.1 compressed-rtf-1.0.7 ctranslate2-4.6.0 dataclasses-json-0.6.7 dnspython-2.7.0 docker-7.1.0 docx2txt-0.8 duckduckgo-search-8.0.2 durationpy-0.10 easygui-0.98.3 ebcdic-1.1.1 ecdsa-0.19.1 elastic-transport-8.17.1 elasticsearch-9.0.1 emoji-2.14.1 eval-type-backport-0.2.2 extract-msg-0.54.1 fake-useragent-2.1.0 fastapi-0.115.7 faster-whisper-1.1.1 filetype-1.2.0 firecrawl-py-1.12.0 fpdf2-2.8.2 fs-2.4.16 ftfy-6.2.3 gcp-storage-emulator-2024.8.3 git-python-1.0.3 google-genai-1.15.0 googleapis-common-protos-1.63.2 greenlet-3.1.1 grpcio-1.67.1 grpcio-status-1.67.1 grpcio-tools-1.67.1 httptools-0.6.4 httpx-sse-0.4.1 humanfriendly-10.0 isodate-0.7.2 jmespath-1.0.1 kubernetes-33.1.0 langchain-0.3.24 langchain-community-0.3.23 langdetect-1.0.9 langfuse-2.44.0 langsmith-0.3.45 lark-1.1.9 ldap3-2.9.1 loguru-0.7.3 markdown-3.7 marshmallow-3.26.1 milvus-lite-2.5.1 mmh3-5.1.0 moto-5.1.6 msal-1.32.3 msal-extensions-1.3.1 msoffcrypto-tool-5.4.2 mypy-extensions-1.1.0 ninja-1.11.1.4 numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 olefile-0.47 oletools-0.60.2 onnxruntime-1.20.1 open-webui-0.6.15 opensearch-py-2.8.0 opentelemetry-api-1.34.1 opentelemetry-exporter-otlp-proto-common-1.34.1 opentelemetry-exporter-otlp-proto-grpc-1.34.1 opentelemetry-instrumentation-0.55b1 opentelemetry-instrumentation-asgi-0.55b1 opentelemetry-instrumentation-fastapi-0.55b1 opentelemetry-proto-1.34.1 opentelemetry-sdk-1.34.1 opentelemetry-semantic-conventions-0.55b1 opentelemetry-util-http-0.55b1 overrides-7.7.0 packaging-23.2 pandas-2.2.3 passlib-1.7.4 pathspec-0.12.1 pcodedmp-1.2.6 peewee-migrate-1.12.2 pgvector-0.4.0 pinecone-6.0.2 pinecone-plugin-interface-0.0.7 playwright-1.49.1 portalocker-2.10.1 posthog-6.0.2 primp-0.15.0 psycopg2-binary-2.9.9 py-partiql-parser-0.6.1 pyasn1-0.4.8 pyasn1-modules-0.4.1 pyclipper-1.3.0.post6 pydantic-2.10.6 pydantic-core-2.27.2 pydantic-settings-2.10.1 pyee-12.0.0 pymdown-extensions-10.14.2 pymilvus-2.5.0 pymongo-4.13.2 pymysql-1.1.1 pypandoc-1.15 pypdf-4.3.1 pypika-0.48.9 pytest-docker-3.1.2 python-dotenv-1.1.1 python-engineio-4.12.2 python-iso639-2025.2.18 python-jose-3.4.0 python-magic-0.4.27 python-oxmsg-0.0.2 python-pptx-1.0.2 python-socketio-5.13.0 pytube-15.0.0 pyxlsb-1.0.10 qdrant-client-1.12.2 rank-bm25-0.2.2 rapidfuzz-3.13.0 rapidocr-onnxruntime-1.4.4 red-black-tree-mod-1.22 redis-6.2.0 requests-2.32.4 responses-0.25.7 restrictedpython-8.0 s3transfer-0.10.4 simple-websocket-1.1.0 sqlalchemy-2.0.38 starlette-0.45.3 starlette-compress-1.6.0 tencentcloud-sdk-python-3.0.1336 typing-inspect-0.9.0 ujson-5.10.0 unstructured-0.16.17 unstructured-client-0.32.3 uvicorn-0.34.2 uvloop-0.21.0 validators-0.35.0 watchfiles-1.1.0 wsproto-1.2.0 xlrd-2.0.1 xmltodict-0.14.2 youtube-transcript-api-1.1.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "238bcdf5ad5c4a278d67991ab31a5ef5",
       "pip_warning": {
        "packages": [
         "google",
         "numpy",
         "packaging"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install open-webui"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
